{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFhVPoTySbdt",
        "outputId": "ac472e54-c0a0-4e28-d9bf-0fdd81dce833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch: 2.8.0+cpu | CUDA available: False\n",
            "Device: cpu | Name: CPU\n"
          ]
        }
      ],
      "source": [
        "# GPU sanity check  (rerun after every restart)\n",
        "import torch\n",
        "\n",
        "gpu_available = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if gpu_available else \"cpu\")\n",
        "gpu_name = torch.cuda.get_device_name(0) if gpu_available else \"CPU\"\n",
        "\n",
        "print(f\"Torch: {torch.__version__} | CUDA available: {gpu_available}\")\n",
        "print(f\"Device: {device} | Name: {gpu_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tytVS_2CSiyh",
        "outputId": "98c61774-775e-4d39-b74e-cbbf1f2c9b39"
      },
      "source": [
        "# CELL 2 — Pin working versions (rerun once after a fresh session)\n",
        "# PyTorch 2.4.0 (CUDA 12.1 build) + matching libs\n",
        "!pip -q install --force-reinstall --no-cache-dir \\\n",
        "  torch==2.4.0+cu121 torchvision==0.19.0+cu121 torchaudio==2.4.0+cu121 \\\n",
        "  --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "!pip -q install --force-reinstall --no-cache-dir \\\n",
        "  numpy==2.0.2 pandas==2.2.2 scikit-learn==1.6.1 matplotlib==3.10.0 seaborn==0.13.2 \\\n",
        "  tqdm==4.66.4 tabulate==0.9.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrSlu9azUZZY",
        "outputId": "c5616720-281d-43ae-9c73-86a50213f1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\Admin\\Desktop\\ffnn-healing\n",
            "Data dir    : c:\\Users\\Admin\\Desktop\\ffnn-healing\\data\n",
            "Models dir  : c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\n",
            "Runs dir    : c:\\Users\\Admin\\Desktop\\ffnn-healing\\experiments\\runs\n"
          ]
        }
      ],
      "source": [
        "#  Project paths RERUN\n",
        "from pathlib import Path\n",
        "\n",
        "def find_project_root(start: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Walk up from 'start' until we find a .git folder (repo root).\n",
        "    If not found, fall back to current working directory.\n",
        "    \"\"\"\n",
        "    for p in [start, *start.parents]:\n",
        "        if (p / \".git\").exists():\n",
        "            return p\n",
        "    return start\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_project_root(Path.cwd())\n",
        "\n",
        "\n",
        "DIRS = [\n",
        "    \"data\",             \n",
        "    \"logs\",             \n",
        "    \"models\",           \n",
        "    \"figures\",          \n",
        "    \"results\",          \n",
        "    \"notebooks\",        \n",
        "    \"experiments/configs\",\n",
        "    \"experiments/runs\", \n",
        "    \"outputs\"          \n",
        "]\n",
        "\n",
        "for d in DIRS:\n",
        "    (PROJECT_ROOT / d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "DATA_DIR    = PROJECT_ROOT / \"data\"\n",
        "MODELS_DIR  = PROJECT_ROOT / \"models\"\n",
        "RUNS_DIR    = PROJECT_ROOT / \"experiments\" / \"runs\"\n",
        "FIG_DIR     = PROJECT_ROOT / \"figures\"\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
        "\n",
        "print(\"Project root:\", PROJECT_ROOT)\n",
        "print(\"Data dir    :\", DATA_DIR)\n",
        "print(\"Models dir  :\", MODELS_DIR)\n",
        "print(\"Runs dir    :\", RUNS_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE0CsIHpYLY_",
        "outputId": "b4667485-a9df-47f9-818d-f87a999cb1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Seed set. Log file will be: c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\experiments_log.csv\n"
          ]
        }
      ],
      "source": [
        "# Utilities, seed, and experiment logging  RERUN\n",
        "import os, random, time\n",
        "from pathlib import Path\n",
        "import torch, numpy as np, pandas as pd\n",
        "\n",
        "# We expect PROJECT_ROOT from the previous \"Project paths\" cell.\n",
        "assert 'PROJECT_ROOT' in globals(), \"Run the Project paths cell first.\"\n",
        "\n",
        "# Device: reuse the 'device' from the GPU sanity cell if present; otherwise detect now\n",
        "DEVICE = globals().get('device', torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def timestamp() -> str:\n",
        "    return time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "def exp_path(kind: str = \"results\") -> Path:\n",
        "    p = PROJECT_ROOT / kind\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "def log_result(row: dict, csv_name: str = \"experiments_log.csv\") -> str:\n",
        "    csv_file = exp_path(\"results\") / csv_name\n",
        "    if csv_file.exists():\n",
        "        df0 = pd.read_csv(csv_file)\n",
        "        df = pd.concat([df0, pd.DataFrame([row])], ignore_index=True)\n",
        "    else:\n",
        "        df = pd.DataFrame([row])\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    return str(csv_file)\n",
        "\n",
        "set_seed(123)\n",
        "print(\"Seed set. Log file will be:\", exp_path('results') / 'experiments_log.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKj8Cq8bZjmx",
        "outputId": "574ef937-ced5-4415-cee7-a61bd27b208a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV exists: True | path: c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\experiments_log.csv\n",
            "         timestamp   phase         note\n",
            "0  20250813-102110  sanity  logger test\n"
          ]
        }
      ],
      "source": [
        "# Logger sanity test   OPTIONAL \n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "row = {\n",
        "    \"timestamp\": timestamp(),  \n",
        "    \"phase\": \"sanity\",\n",
        "    \"note\": \"logger test\"\n",
        "}\n",
        "csv_file = log_result(row)      \n",
        "\n",
        "csv_path = Path(csv_file)\n",
        "print(\"CSV exists:\", csv_path.exists(), \"| path:\", csv_path)\n",
        "print(pd.read_csv(csv_path).tail(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMeE3MAfZzhC",
        "outputId": "88673cce-26a8-46af-872c-4b97a88af420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[breast_cancer] Saved. features=30 | splits={'train': 398, 'val': 85, 'test': 86}\n",
            "  Class balance (train/val/test): {'train': {1: 250, 0: 148}, 'val': {1: 53, 0: 32}, 'test': {1: 54, 0: 32}}\n",
            "[california_housing] Saved. features=8 | splits={'train': 14448, 'val': 3096, 'test': 3096}\n",
            "\n",
            "Saved folders:\n",
            "c:\\Users\\Admin\\Desktop\\ffnn-healing\\data\n",
            "├─ breast_cancer\n",
            "│  └─ meta.json\n",
            "│  └─ scaler.joblib\n",
            "│  └─ X_test.npy\n",
            "│  └─ X_train.npy\n",
            "│  └─ X_val.npy\n",
            "│  └─ y_test.npy\n",
            "│  └─ y_train.npy\n",
            "│  └─ y_val.npy\n",
            "├─ california_housing\n",
            "│  └─ meta.json\n",
            "│  └─ scaler.joblib\n",
            "│  └─ X_test.npy\n",
            "│  └─ X_train.npy\n",
            "│  └─ X_val.npy\n",
            "│  └─ y_test.npy\n",
            "│  └─ y_train.npy\n",
            "│  └─ y_val.npy\n"
          ]
        }
      ],
      "source": [
        "# DATASET PREP (Option A)\n",
        "# RUN-WHEN-CHANGING-CONFIG \n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np, os, json, joblib, pandas as pd, collections\n",
        "from pathlib import Path\n",
        "\n",
        "set_seed(42)  # from our utilities cell\n",
        "\n",
        "# Use project-local data directory (created earlier)\n",
        "DATA_ROOT = DATA_DIR  # from the Project paths cell\n",
        "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def split_scale_save(X, y, name, task_type, feature_names=None):\n",
        "    \"\"\"\n",
        "    Splits (70/15/15), scales features (fit on train), saves arrays+scaler+meta to disk.\n",
        "    task_type: 'clf' or 'reg'\n",
        "    \"\"\"\n",
        "    # Split\n",
        "    strat = y if task_type == \"clf\" else None\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
        "        X, y, test_size=0.30, random_state=42, stratify=strat\n",
        "    )\n",
        "    strat_tmp = y_tmp if task_type == \"clf\" else None\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_tmp, y_tmp, test_size=0.50, random_state=42, stratify=strat_tmp\n",
        "    )\n",
        "\n",
        "    # Scale features using train stats only\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    X_train = scaler.transform(X_train).astype(np.float32)\n",
        "    X_val   = scaler.transform(X_val).astype(np.float32)\n",
        "    X_test  = scaler.transform(X_test).astype(np.float32)\n",
        "\n",
        "    # Ensure y dtypes\n",
        "    if task_type == \"clf\":\n",
        "        y_train = y_train.astype(np.int64); y_val = y_val.astype(np.int64); y_test = y_test.astype(np.int64)\n",
        "    else:\n",
        "        y_train = y_train.astype(np.float32); y_val = y_val.astype(np.float32); y_test = y_test.astype(np.float32)\n",
        "\n",
        "    # Save\n",
        "    OUT = DATA_ROOT / name\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(OUT / \"X_train.npy\", X_train); np.save(OUT / \"y_train.npy\", y_train)\n",
        "    np.save(OUT / \"X_val.npy\",   X_val);   np.save(OUT / \"y_val.npy\",   y_val)\n",
        "    np.save(OUT / \"X_test.npy\",  X_test);  np.save(OUT / \"y_test.npy\",  y_test)\n",
        "    joblib.dump(scaler, OUT / \"scaler.joblib\")\n",
        "\n",
        "    # Metadata\n",
        "    meta = {\n",
        "        \"name\": name,\n",
        "        \"task\": task_type,\n",
        "        \"n_features\": int(X_train.shape[1]),\n",
        "        \"splits\": {\"train\": int(len(y_train)), \"val\": int(len(y_val)), \"test\": int(len(y_test))},\n",
        "        \"feature_names\": list(feature_names) if feature_names is not None else None\n",
        "    }\n",
        "    if task_type == \"clf\":\n",
        "        meta[\"class_counts\"] = {\n",
        "            \"train\": {int(k): int(v) for k,v in collections.Counter(y_train).items()},\n",
        "            \"val\":   {int(k): int(v) for k,v in collections.Counter(y_val).items()},\n",
        "            \"test\":  {int(k): int(v) for k,v in collections.Counter(y_test).items()},\n",
        "        }\n",
        "\n",
        "    with open(OUT / \"meta.json\", \"w\") as f:\n",
        "        f.write(json.dumps(meta, indent=2))\n",
        "\n",
        "    # Log a one-line summary to our experiments log\n",
        "    log_result({\n",
        "        \"timestamp\": timestamp(),\n",
        "        \"phase\": \"data_prep\",\n",
        "        \"dataset\": name,\n",
        "        \"task\": task_type,\n",
        "        \"n_features\": meta[\"n_features\"],\n",
        "        \"train\": meta[\"splits\"][\"train\"],\n",
        "        \"val\": meta[\"splits\"][\"val\"],\n",
        "        \"test\": meta[\"splits\"][\"test\"]\n",
        "    })\n",
        "\n",
        "    print(f\"[{name}] Saved. features={meta['n_features']} | splits={meta['splits']}\")\n",
        "    if task_type == \"clf\":\n",
        "        print(f\"  Class balance (train/val/test): {meta['class_counts']}\")\n",
        "    return meta\n",
        "\n",
        "# ---- Classification: Breast Cancer (binary) ----\n",
        "bc = load_breast_cancer()\n",
        "meta_bc = split_scale_save(\n",
        "    bc.data, bc.target, name=\"breast_cancer\", task_type=\"clf\", feature_names=bc.feature_names\n",
        ")\n",
        "\n",
        "# ---- Regression: California Housing ----\n",
        "cal = fetch_california_housing()\n",
        "meta_cal = split_scale_save(\n",
        "    cal.data, cal.target, name=\"california_housing\", task_type=\"reg\", feature_names=cal.feature_names\n",
        ")\n",
        "\n",
        "def print_tree(root: Path, max_depth=2, prefix=\"\"):\n",
        "    root = Path(root)\n",
        "    def _walk(p: Path, depth: int, pref: str):\n",
        "        if depth > max_depth: \n",
        "            return\n",
        "        for child in sorted(p.iterdir()):\n",
        "            print(pref + (\"└─ \" if child.is_file() else \"├─ \") + child.name)\n",
        "            if child.is_dir():\n",
        "                _walk(child, depth+1, pref + \"│  \")\n",
        "    print(str(root))\n",
        "    _walk(root, 0, \"\")\n",
        "    \n",
        "print(\"\\nSaved folders:\")\n",
        "print_tree(DATA_ROOT, max_depth=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGc544Hgc8Io",
        "outputId": "c7dc8c94-97fa-4a64-ff31-3cacb5bac646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Ready. Torch: 2.4.0+cu121 | Device: cuda | Root: /content/drive/MyDrive/FFNN_Healing_Thesis\n"
          ]
        }
      ],
      "source": [
        "# === MINIMAL BOOTSTRAP (run after every restart) ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, random, time, torch, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/FFNN_Healing_Thesis\")\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def timestamp(): return time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "def exp_path(kind=\"results\"):\n",
        "    p = PROJECT_ROOT / kind\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "def log_result(row: dict, csv_name=\"experiments_log.csv\"):\n",
        "    csv_file = exp_path(\"results\") / csv_name\n",
        "    df = pd.DataFrame([row])\n",
        "    if csv_file.exists():\n",
        "        df0 = pd.read_csv(csv_file); df = pd.concat([df0, df], ignore_index=True)\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    return str(csv_file)\n",
        "\n",
        "print(\"Ready. Torch:\", torch.__version__, \"| Device:\", DEVICE, \"| Root:\", PROJECT_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ugwlz1C-d2P9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Commons ready ✓  | DEVICE: cpu\n"
          ]
        }
      ],
      "source": [
        "# COMMONS \n",
        "# RERUN-AFTER-RESTART\n",
        "\n",
        "import os, json, math, time\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Reuse what we already set earlier\n",
        "assert 'PROJECT_ROOT' in globals(), \"Run the Project paths cell first.\"\n",
        "assert 'FIG_DIR' in globals() and 'MODELS_DIR' in globals() and 'RESULTS_DIR' in globals(), \"Project dirs not set.\"\n",
        "DEVICE = globals().get('device', torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "set_seed(42)\n",
        "\n",
        "# Ensure dirs exist (safe if they already do)\n",
        "for d in [FIG_DIR, MODELS_DIR, RESULTS_DIR]:\n",
        "    Path(d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "class NumpyDataset(Dataset):\n",
        "    def __init__(self, X_path, y_path, task):\n",
        "        self.X = np.load(X_path).astype(np.float32)\n",
        "        self.y = np.load(y_path)\n",
        "        self.task = task\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, i):\n",
        "        x = torch.from_numpy(self.X[i])\n",
        "        if self.task == \"clf\":\n",
        "            y = torch.tensor(int(self.y[i]), dtype=torch.long)\n",
        "        else:\n",
        "            y = torch.tensor(float(self.y[i]), dtype=torch.float32).unsqueeze(0)\n",
        "        return x, y\n",
        "\n",
        "def make_loaders(data_dir, task, batch_size=128):\n",
        "    data_dir = Path(data_dir)\n",
        "    ds_train = NumpyDataset(data_dir/\"X_train.npy\", data_dir/\"y_train.npy\", task)\n",
        "    ds_val   = NumpyDataset(data_dir/\"X_val.npy\",   data_dir/\"y_val.npy\",   task)\n",
        "    ds_test  = NumpyDataset(data_dir/\"X_test.npy\",  data_dir/\"y_test.npy\",  task)\n",
        "    train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "    val_loader   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "    test_loader  = DataLoader(ds_test,  batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "    n_features = ds_train.X.shape[1]\n",
        "    return train_loader, val_loader, test_loader, n_features\n",
        "\n",
        "def init_kaiming(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "class FFNN_Classifier(nn.Module):\n",
        "    def __init__(self, n_in, hidden=[64, 64, 32], n_out=2, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers, prev = [], n_in\n",
        "        for h in hidden:\n",
        "            layers += [nn.Linear(prev, h), nn.ReLU(), nn.Dropout(p_drop)]\n",
        "            prev = h\n",
        "        layers += [nn.Linear(prev, n_out)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.apply(init_kaiming)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class FFNN_Regression(nn.Module):\n",
        "    def __init__(self, n_in, hidden=[64, 64, 32], p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers, prev = [], n_in\n",
        "        for h in hidden:\n",
        "            layers += [nn.Linear(prev, h), nn.ReLU(), nn.Dropout(p_drop)]\n",
        "            prev = h\n",
        "        layers += [nn.Linear(prev, 1)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.apply(init_kaiming)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, task, max_epochs=200, lr=1e-3, weight_decay=1e-4, patience=20, run_name=\"run\"):\n",
        "    model = model.to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss() if task==\"clf\" else nn.MSELoss()\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "\n",
        "    history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_metric\": []}\n",
        "    best_val, best_path, epochs_no_improve = float(\"inf\"), Path(MODELS_DIR) / f\"{run_name}_{timestamp()}_best.pt\", 0\n",
        "\n",
        "    for epoch in range(1, max_epochs+1):\n",
        "        model.train(); train_losses = []\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb if task==\"clf\" else yb)\n",
        "            loss.backward(); opt.step()\n",
        "            train_losses.append(loss.item())\n",
        "        train_loss = float(np.mean(train_losses)) if train_losses else 0.0\n",
        "\n",
        "        model.eval(); val_losses = []; y_true_list, y_pred_list = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "                out = model(xb)\n",
        "                loss = criterion(out, yb if task==\"clf\" else yb)\n",
        "                val_losses.append(loss.item())\n",
        "                if task == \"clf\":\n",
        "                    preds = out.argmax(dim=1).detach().cpu().numpy()\n",
        "                    y_true_list.append(yb.detach().cpu().numpy())\n",
        "                    y_pred_list.append(preds)\n",
        "                else:\n",
        "                    y_true_list.append(yb.detach().cpu().numpy().squeeze())\n",
        "                    y_pred_list.append(out.detach().cpu().numpy().squeeze())\n",
        "        val_loss = float(np.mean(val_losses)) if val_losses else 0.0\n",
        "\n",
        "        if task == \"clf\":\n",
        "            y_true = np.concatenate(y_true_list); y_pred = np.concatenate(y_pred_list)\n",
        "            val_metric = float(accuracy_score(y_true, y_pred))\n",
        "        else:\n",
        "            y_true = np.array(np.concatenate([np.atleast_1d(a) for a in y_true_list]))\n",
        "            y_pred = np.array(np.concatenate([np.atleast_1d(a) for a in y_pred_list]))\n",
        "            val_metric = float(math.sqrt(mean_squared_error(y_true, y_pred)))\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        history[\"epoch\"].append(epoch); history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss); history[\"val_metric\"].append(val_metric)\n",
        "\n",
        "        if val_loss < best_val - 1e-8:\n",
        "            best_val = val_loss; epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), best_path); best_mark=\"*\"\n",
        "        else:\n",
        "            epochs_no_improve += 1; best_mark=\"\"\n",
        "        if epoch % 10 == 0 or best_mark == \"*\":\n",
        "            print(f\"[{run_name}] epoch {epoch:03d} | train {train_loss:.4f} | val {val_loss:.4f} | metric {val_metric:.4f} {best_mark}\")\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"[{run_name}] Early stopping at epoch {epoch}. Best val_loss={best_val:.4f}\")\n",
        "            break\n",
        "    return best_path, history\n",
        "\n",
        "def evaluate_model(model, loader, task):\n",
        "    model.eval(); y_true_list, y_pred_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            out = model(xb)\n",
        "            if task == \"clf\":\n",
        "                preds = out.argmax(dim=1)\n",
        "                y_true_list.append(yb.cpu().numpy()); y_pred_list.append(preds.cpu().numpy())\n",
        "            else:\n",
        "                y_true_list.append(yb.cpu().numpy().squeeze()); y_pred_list.append(out.cpu().numpy().squeeze())\n",
        "    if task == \"clf\":\n",
        "        y_true = np.concatenate(y_true_list); y_pred = np.concatenate(y_pred_list)\n",
        "        return {\"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
        "                \"f1\": float(f1_score(y_true, y_pred, zero_division=0))}\n",
        "    else:\n",
        "        y_true = np.array(np.concatenate([np.atleast_1d(a) for a in y_true_list]))\n",
        "        y_pred = np.array(np.concatenate([np.atleast_1d(a) for a in y_pred_list]))\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        return {\"mae\": float(mae), \"rmse\": float(rmse)}\n",
        "\n",
        "def plot_history(history, run_name, task):\n",
        "    fig = plt.figure(figsize=(6,4))\n",
        "    plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"train_loss\")\n",
        "    plt.plot(history[\"epoch\"], history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.title(f\"{run_name} loss\")\n",
        "    fig_path1 = Path(FIG_DIR) / f\"{run_name}_loss.png\"\n",
        "    plt.savefig(fig_path1, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "    fig = plt.figure(figsize=(6,4))\n",
        "    ylabel = \"accuracy\" if task==\"clf\" else \"RMSE\"\n",
        "    plt.plot(history[\"epoch\"], history[\"val_metric\"], label=f\"val_{ylabel}\")\n",
        "    plt.xlabel(\"epoch\"); plt.ylabel(ylabel); plt.legend(); plt.title(f\"{run_name} {ylabel}\")\n",
        "    fig_path2 = Path(FIG_DIR) / f\"{run_name}_{ylabel}.png\"\n",
        "    plt.savefig(fig_path2, bbox_inches=\"tight\"); plt.close()\n",
        "    return str(fig_path1), str(fig_path2)\n",
        "\n",
        "print(\"Commons ready ✓  | DEVICE:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgNzxzUKeYaA",
        "outputId": "d912bf95-ce56-4c0b-f185-82baeebc408f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_features: 30\n",
            "[clf_breast_cancer_baseline] epoch 001 | train 0.6813 | val 0.4313 | metric 0.9059 *\n",
            "[clf_breast_cancer_baseline] epoch 002 | train 0.4232 | val 0.3212 | metric 0.9412 *\n",
            "[clf_breast_cancer_baseline] epoch 003 | train 0.3494 | val 0.2498 | metric 0.9647 *\n",
            "[clf_breast_cancer_baseline] epoch 004 | train 0.2894 | val 0.2014 | metric 0.9529 *\n",
            "[clf_breast_cancer_baseline] epoch 005 | train 0.2403 | val 0.1667 | metric 0.9529 *\n",
            "[clf_breast_cancer_baseline] epoch 006 | train 0.1997 | val 0.1404 | metric 0.9529 *\n",
            "[clf_breast_cancer_baseline] epoch 007 | train 0.2006 | val 0.1206 | metric 0.9647 *\n",
            "[clf_breast_cancer_baseline] epoch 008 | train 0.2253 | val 0.1066 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 009 | train 0.1667 | val 0.0989 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 010 | train 0.1386 | val 0.0924 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 011 | train 0.1131 | val 0.0865 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 012 | train 0.1322 | val 0.0810 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 013 | train 0.2014 | val 0.0754 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 014 | train 0.0980 | val 0.0734 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 015 | train 0.1482 | val 0.0715 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 016 | train 0.1037 | val 0.0700 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 017 | train 0.0899 | val 0.0684 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 018 | train 0.1079 | val 0.0663 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 019 | train 0.0737 | val 0.0636 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 020 | train 0.0837 | val 0.0611 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 021 | train 0.0781 | val 0.0587 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 022 | train 0.0897 | val 0.0560 | metric 0.9882 *\n",
            "[clf_breast_cancer_baseline] epoch 023 | train 0.0729 | val 0.0545 | metric 0.9882 *\n",
            "[clf_breast_cancer_baseline] epoch 024 | train 0.0820 | val 0.0541 | metric 0.9882 *\n",
            "[clf_breast_cancer_baseline] epoch 027 | train 0.1012 | val 0.0541 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 030 | train 0.0578 | val 0.0533 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 031 | train 0.0717 | val 0.0520 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 032 | train 0.0476 | val 0.0505 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 033 | train 0.0746 | val 0.0498 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 034 | train 0.0469 | val 0.0481 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 035 | train 0.0524 | val 0.0476 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 036 | train 0.0660 | val 0.0472 | metric 0.9765 *\n",
            "[clf_breast_cancer_baseline] epoch 040 | train 0.0376 | val 0.0629 | metric 0.9765 \n",
            "[clf_breast_cancer_baseline] epoch 050 | train 0.0424 | val 0.0658 | metric 0.9765 \n",
            "[clf_breast_cancer_baseline] Early stopping at epoch 56. Best val_loss=0.0472\n",
            "TEST metrics: {'accuracy': 0.9534883720930233, 'f1': 0.9629629629629629}\n",
            "Saved plots: c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\clf_breast_cancer_baseline_loss.png | c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\clf_breast_cancer_baseline_accuracy.png\n",
            "Best model path: c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf_breast_cancer_baseline_20250813-103737_best.pt\n",
            "Metrics saved to: c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\clf_breast_cancer_baseline_20250813-103739_metrics.json\n"
          ]
        }
      ],
      "source": [
        "# Baseline training — Breast Cancer \n",
        "from pathlib import Path\n",
        "import json, torch\n",
        "\n",
        "\n",
        "BREAST_DIR = DATA_DIR / \"breast_cancer\"\n",
        "assert (BREAST_DIR / \"X_train.npy\").exists(), \"Run the dataset prep cell first to create local splits.\"\n",
        "\n",
        "train_loader, val_loader, test_loader, n_features = make_loaders(BREAST_DIR, task=\"clf\", batch_size=128)\n",
        "print(\"n_features:\", n_features)\n",
        "\n",
        "run_name = \"clf_breast_cancer_baseline\"\n",
        "model_clf = FFNN_Classifier(n_in=n_features, hidden=[64,64,32], n_out=2, p_drop=0.1)\n",
        "\n",
        "best_path, hist = train_model(\n",
        "    model_clf, train_loader, val_loader, task=\"clf\",\n",
        "    max_epochs=200, lr=1e-3, weight_decay=1e-4, patience=20, run_name=run_name\n",
        ")\n",
        "\n",
        "# Evaluate best checkpoint on test\n",
        "best_model = FFNN_Classifier(n_in=n_features, hidden=[64,64,32], n_out=2, p_drop=0.1).to(DEVICE)\n",
        "best_model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
        "metrics_test = evaluate_model(best_model, test_loader, task=\"clf\")\n",
        "print(\"TEST metrics:\", metrics_test)\n",
        "\n",
        "# Plots + metrics\n",
        "fig_loss, fig_metric = plot_history(hist, run_name, task=\"clf\")\n",
        "metrics_path = Path(RESULTS_DIR) / f\"{run_name}_{timestamp()}_metrics.json\"\n",
        "with open(metrics_path, \"w\") as f:\n",
        "    json.dump({\"test\": metrics_test}, f, indent=2)\n",
        "\n",
        "# Log run summary to CSV\n",
        "log_result({\n",
        "    \"timestamp\": timestamp(),\n",
        "    \"phase\": \"baseline\",\n",
        "    \"dataset\": \"breast_cancer\",\n",
        "    \"task\": \"clf\",\n",
        "    \"model\": \"FFNN_Classifier[64,64,32]\",\n",
        "    \"test_accuracy\": metrics_test[\"accuracy\"],\n",
        "    \"test_f1\": metrics_test[\"f1\"],\n",
        "    \"best_ckpt\": str(best_path),\n",
        "    \"fig_loss\": fig_loss,\n",
        "    \"fig_metric\": fig_metric\n",
        "})\n",
        "\n",
        "print(\"Saved plots:\", fig_loss, \"|\", fig_metric)\n",
        "print(\"Best model path:\", best_path)\n",
        "print(\"Metrics saved to:\", metrics_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGPSf8qFe1Qd",
        "outputId": "f0d3c6fa-198f-4f5e-c262-ea72722cf0a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_features: 8\n",
            "[reg_california_baseline] epoch 001 | train 2.2803 | val 0.9713 | metric 0.9606 *\n",
            "[reg_california_baseline] epoch 002 | train 1.0828 | val 0.7501 | metric 0.8398 *\n",
            "[reg_california_baseline] epoch 003 | train 0.8886 | val 0.6839 | metric 0.7993 *\n",
            "[reg_california_baseline] epoch 004 | train 0.8055 | val 0.5888 | metric 0.7460 *\n",
            "[reg_california_baseline] epoch 005 | train 0.7231 | val 0.5782 | metric 0.7338 *\n",
            "[reg_california_baseline] epoch 006 | train 0.8544 | val 0.5396 | metric 0.6977 *\n",
            "[reg_california_baseline] epoch 007 | train 0.6485 | val 0.5157 | metric 0.6987 *\n",
            "[reg_california_baseline] epoch 008 | train 0.6164 | val 0.4713 | metric 0.6667 *\n",
            "[reg_california_baseline] epoch 009 | train 0.5646 | val 0.4703 | metric 0.6645 *\n",
            "[reg_california_baseline] epoch 010 | train 0.7211 | val 0.4758 | metric 0.6679 \n",
            "[reg_california_baseline] epoch 011 | train 0.5638 | val 0.4542 | metric 0.6617 *\n",
            "[reg_california_baseline] epoch 012 | train 0.5220 | val 0.4320 | metric 0.6394 *\n",
            "[reg_california_baseline] epoch 017 | train 0.4884 | val 0.4102 | metric 0.6267 *\n",
            "[reg_california_baseline] epoch 019 | train 0.4387 | val 0.4006 | metric 0.6181 *\n",
            "[reg_california_baseline] epoch 020 | train 0.4470 | val 0.3884 | metric 0.6117 *\n",
            "[reg_california_baseline] epoch 025 | train 0.4212 | val 0.3817 | metric 0.6075 *\n",
            "[reg_california_baseline] epoch 026 | train 0.4275 | val 0.3794 | metric 0.6083 *\n",
            "[reg_california_baseline] epoch 027 | train 0.4123 | val 0.3744 | metric 0.6047 *\n",
            "[reg_california_baseline] epoch 030 | train 0.4012 | val 0.3911 | metric 0.6120 \n",
            "[reg_california_baseline] epoch 034 | train 0.3881 | val 0.3725 | metric 0.5962 *\n",
            "[reg_california_baseline] epoch 036 | train 0.3882 | val 0.3684 | metric 0.5929 *\n",
            "[reg_california_baseline] epoch 037 | train 0.3811 | val 0.3606 | metric 0.5867 *\n",
            "[reg_california_baseline] epoch 040 | train 0.3720 | val 0.3481 | metric 0.5817 *\n",
            "[reg_california_baseline] epoch 044 | train 0.3734 | val 0.3463 | metric 0.5805 *\n",
            "[reg_california_baseline] epoch 050 | train 0.3946 | val 0.3540 | metric 0.5845 \n",
            "[reg_california_baseline] epoch 058 | train 0.3590 | val 0.3437 | metric 0.5776 *\n",
            "[reg_california_baseline] epoch 060 | train 0.3577 | val 0.3478 | metric 0.5812 \n",
            "[reg_california_baseline] epoch 061 | train 0.3586 | val 0.3433 | metric 0.5774 *\n",
            "[reg_california_baseline] epoch 062 | train 0.3590 | val 0.3428 | metric 0.5766 *\n",
            "[reg_california_baseline] epoch 070 | train 0.3604 | val 0.3482 | metric 0.5806 \n",
            "[reg_california_baseline] epoch 080 | train 0.3567 | val 0.3467 | metric 0.5794 \n",
            "[reg_california_baseline] Early stopping at epoch 87. Best val_loss=0.3428\n",
            "TEST metrics: {'mae': 0.37485018372535706, 'rmse': 0.5373355181330539}\n",
            "Saved plots: c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\reg_california_baseline_loss.png | c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\reg_california_baseline_RMSE.png\n",
            "Best model path: c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg_california_baseline_20250813-104035_best.pt\n",
            "Metrics saved to: c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\reg_california_baseline_20250813-104136_metrics.json\n"
          ]
        }
      ],
      "source": [
        "# === REGRESSION BASELINE (California Housing) \n",
        "from pathlib import Path\n",
        "import json, torch\n",
        "\n",
        "CAL_DIR = DATA_DIR / \"california_housing\"   \n",
        "assert (CAL_DIR / \"X_train.npy\").exists(), \"Run the dataset prep cell first to create local splits.\"\n",
        "\n",
        "train_loader, val_loader, test_loader, n_features = make_loaders(CAL_DIR, task=\"reg\", batch_size=256)\n",
        "print(\"n_features:\", n_features)\n",
        "\n",
        "run_name = \"reg_california_baseline\"\n",
        "model_reg = FFNN_Regression(n_in=n_features, hidden=[128,64,32], p_drop=0.1)\n",
        "\n",
        "best_path, hist = train_model(\n",
        "    model_reg, train_loader, val_loader, task=\"reg\",\n",
        "    max_epochs=250, lr=1e-3, weight_decay=1e-4, patience=25, run_name=run_name\n",
        ")\n",
        "\n",
        "# Load best checkpoint and evaluate on test\n",
        "best_model = FFNN_Regression(n_in=n_features, hidden=[128,64,32], p_drop=0.1).to(DEVICE)\n",
        "state = torch.load(best_path, map_location=DEVICE)   \n",
        "best_model.load_state_dict(state)\n",
        "\n",
        "metrics_test = evaluate_model(best_model, test_loader, task=\"reg\")\n",
        "print(\"TEST metrics:\", metrics_test) \n",
        "\n",
        "# Plots + metrics file\n",
        "fig_loss, fig_metric = plot_history(hist, run_name, task=\"reg\")\n",
        "metrics_path = Path(RESULTS_DIR) / f\"{run_name}_{timestamp()}_metrics.json\"\n",
        "with open(metrics_path, \"w\") as f:\n",
        "    json.dump({\"test\": metrics_test}, f, indent=2)\n",
        "\n",
        "# Log run summary to CSV\n",
        "log_result({\n",
        "    \"timestamp\": timestamp(),\n",
        "    \"phase\": \"baseline\",\n",
        "    \"dataset\": \"california_housing\",\n",
        "    \"task\": \"reg\",\n",
        "    \"model\": \"FFNN_Regression[128,64,32]\",\n",
        "    \"test_mae\": metrics_test[\"mae\"],\n",
        "    \"test_rmse\": metrics_test[\"rmse\"],\n",
        "    \"best_ckpt\": str(best_path),\n",
        "    \"fig_loss\": fig_loss,\n",
        "    \"fig_metric\": fig_metric\n",
        "})\n",
        "\n",
        "print(\"Saved plots:\", fig_loss, \"|\", fig_metric)\n",
        "print(\"Best model path:\", best_path)\n",
        "print(\"Metrics saved to:\", metrics_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NK9Gxp8-fZej"
      },
      "outputs": [],
      "source": [
        "#  DAMAGE ENGINE\n",
        "# RERUN-AFTER-RESTART\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "\n",
        "# Re-use: DEVICE, set_seed, log_result, evaluate_model, make_loaders, timestamp,\n",
        "# PROJECT_ROOT, MODELS_DIR, RESULTS_DIR already defined earlier.\n",
        "assert 'PROJECT_ROOT' in globals(), \"Run the Project paths cell first.\"\n",
        "assert 'RESULTS_DIR' in globals(), \"Run the Project paths cell first (defines RESULTS_DIR).\"\n",
        "\n",
        "def get_linear_layers(model: nn.Module):\n",
        "    \"\"\"Return list of (seq_index_in_model_net, linear_module) for nn.Linear layers in forward order.\"\"\"\n",
        "    layers = []\n",
        "    for i, m in enumerate(model.net):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            layers.append((i, m))\n",
        "    return layers\n",
        "\n",
        "def summarize_linear_layers(model):\n",
        "    \"\"\"Return a list of dicts describing each Linear layer (useful to pick which layer to damage).\"\"\"\n",
        "    info = []\n",
        "    for li, lin in get_linear_layers(model):\n",
        "        info.append({\"seq_index\": li, \"in_features\": lin.in_features, \"out_features\": lin.out_features})\n",
        "    return info\n",
        "\n",
        "def clone_from_checkpoint(model_ctor, ckpt_path: str):\n",
        "    \"\"\"\n",
        "    Build a fresh model via `model_ctor()` and load weights from `ckpt_path`.\n",
        "    `model_ctor` should be a zero-arg function returning an *already-constructed* model with the same architecture.\n",
        "    \"\"\"\n",
        "    m = model_ctor().to(DEVICE)\n",
        "    try:\n",
        "        state = torch.load(ckpt_path, map_location=DEVICE, weights_only=True)  # newer torch\n",
        "    except TypeError:\n",
        "        state = torch.load(ckpt_path, map_location=DEVICE)                     # older torch\n",
        "    m.load_state_dict(state)\n",
        "    return m\n",
        "\n",
        "def damage_neurons_in_layer(model: nn.Module, layer_lin_seq_index: int, pct_neurons: float, rng: np.random.Generator):\n",
        "    \"\"\"\n",
        "    Damage a percentage of *neurons* in a given Linear layer:\n",
        "    - Zero the corresponding rows of this layer's weight (incoming weights) and its bias.\n",
        "    - Also zero the corresponding *columns* in the *next* Linear layer (outgoing connections),\n",
        "      if a next Linear layer exists.\n",
        "    Returns list of damaged neuron indices (relative to that layer).\n",
        "    \"\"\"\n",
        "    linear_layers = get_linear_layers(model)\n",
        "    # find target linear by its seq index inside model.net\n",
        "    target_pos = None\n",
        "    for pos, (seq_i, _) in enumerate(linear_layers):\n",
        "        if seq_i == layer_lin_seq_index:\n",
        "            target_pos = pos\n",
        "            break\n",
        "    assert target_pos is not None, f\"No nn.Linear at seq index {layer_lin_seq_index} in model.net\"\n",
        "\n",
        "    target_seq_i, target_lin = linear_layers[target_pos]\n",
        "    out_feats = target_lin.out_features\n",
        "    n_dmg = max(1, int(round(pct_neurons * out_feats)))\n",
        "    dmg_neurons = rng.choice(out_feats, size=n_dmg, replace=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # zero incoming weights + bias for damaged neurons\n",
        "        W = target_lin.weight  # [out_features, in_features]\n",
        "        W[dmg_neurons, :] = 0.0\n",
        "        if target_lin.bias is not None:\n",
        "            target_lin.bias[dmg_neurons] = 0.0\n",
        "\n",
        "        # zero outgoing connections in the next linear (columns)\n",
        "        if target_pos + 1 < len(linear_layers):\n",
        "            _, next_lin = linear_layers[target_pos + 1]\n",
        "            next_lin.weight[:, dmg_neurons] = 0.0\n",
        "\n",
        "    return dmg_neurons.tolist()\n",
        "\n",
        "def damage_weights_in_layer(model: nn.Module, layer_lin_seq_index: int, pct_weights: float, rng: np.random.Generator, mode=\"random\"):\n",
        "    \"\"\"\n",
        "    Damage a percentage of *weights* in a given Linear layer:\n",
        "    - mode='random': independent random mask over all weights\n",
        "    - mode='block' : zero a contiguous rectangular block (for 'specific area' effect)\n",
        "    Returns number of weights zeroed.\n",
        "    \"\"\"\n",
        "    target_lin = None\n",
        "    for seq_i, lin in get_linear_layers(model):\n",
        "        if seq_i == layer_lin_seq_index:\n",
        "            target_lin = lin\n",
        "            break\n",
        "    assert target_lin is not None, f\"No nn.Linear at seq index {layer_lin_seq_index} in model.net\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        W = target_lin.weight  # [out_features, in_features]\n",
        "        H, K = W.shape\n",
        "        total = H * K\n",
        "        n_dmg = max(1, int(round(pct_weights * total)))\n",
        "\n",
        "        if mode == \"random\":\n",
        "            idx = rng.choice(total, size=n_dmg, replace=False)\n",
        "            rows = (idx // K).astype(int)\n",
        "            cols = (idx % K).astype(int)\n",
        "            W[rows, cols] = 0.0\n",
        "        elif mode == \"block\":\n",
        "            # choose a block whose area ≈ n_dmg\n",
        "            h = max(1, int(round(np.sqrt(n_dmg))))\n",
        "            k = max(1, int(round(n_dmg / h)))\n",
        "            r0 = int(rng.integers(0, max(1, H - h + 1)))\n",
        "            c0 = int(rng.integers(0, max(1, K - k + 1)))\n",
        "            W[r0:r0+h, c0:c0+k] = 0.0\n",
        "        else:\n",
        "            raise ValueError(\"mode must be 'random' or 'block'\")\n",
        "\n",
        "    return n_dmg\n",
        "\n",
        "def eval_task(model_ctor, ckpt_path, task, data_dir, damage_fn=None, repeats=1, **damage_kwargs):\n",
        "    \"\"\"\n",
        "    Load a fresh model from checkpoint, optionally apply damage cumulatively, and evaluate after each step.\n",
        "    Returns: list of dicts with keys {'repeat': int, 'metrics': {...}} where repeat=0 is the baseline.\n",
        "    \"\"\"\n",
        "    set_seed(42)\n",
        "    if task == \"clf\":\n",
        "        _, _, test_loader, _ = make_loaders(data_dir, \"clf\", batch_size=256)\n",
        "    else:\n",
        "        _, _, test_loader, _ = make_loaders(data_dir, \"reg\", batch_size=512)\n",
        "\n",
        "    # baseline\n",
        "    model = clone_from_checkpoint(model_ctor, ckpt_path)\n",
        "    out = [{\"repeat\": 0, \"metrics\": evaluate_model(model, test_loader, task)}]\n",
        "\n",
        "    if damage_fn is None or repeats <= 0:\n",
        "        return out\n",
        "\n",
        "    rng = np.random.default_rng(12345)\n",
        "    # progressive (cumulative) damage\n",
        "    for r in range(1, repeats + 1):\n",
        "        damage_fn(model, **damage_kwargs, rng=rng)\n",
        "        m = evaluate_model(model, test_loader, task)\n",
        "        out.append({\"repeat\": r, \"metrics\": m})\n",
        "    return out\n",
        "\n",
        "def save_experiment_log(rows, csv_name=\"damage_immediate_drop.csv\"):\n",
        "    \"\"\"\n",
        "    Append rows to a results CSV in RESULTS_DIR.\n",
        "    Each row should already be a flat dict (add your own metadata before calling).\n",
        "    \"\"\"\n",
        "    for row in rows:\n",
        "        log_result(row, csv_name=csv_name)  # uses RESULTS_DIR internally\n",
        "    return str(Path(RESULTS_DIR) / csv_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi2TA-LEgHBi",
        "outputId": "925b91f1-fa9a-499e-9c99-c3b0c52cd584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLF_CKPT: c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf_breast_cancer_baseline_20250813-103737_best.pt\n",
            "REG_CKPT: c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg_california_baseline_20250813-104035_best.pt\n",
            "Classifier linear layers: [{'seq_index': 0, 'in_features': 30, 'out_features': 64}, {'seq_index': 3, 'in_features': 64, 'out_features': 64}, {'seq_index': 6, 'in_features': 64, 'out_features': 32}, {'seq_index': 9, 'in_features': 32, 'out_features': 2}]\n",
            "Regression linear layers: [{'seq_index': 0, 'in_features': 8, 'out_features': 128}, {'seq_index': 3, 'in_features': 128, 'out_features': 64}, {'seq_index': 6, 'in_features': 64, 'out_features': 32}, {'seq_index': 9, 'in_features': 32, 'out_features': 1}]\n"
          ]
        }
      ],
      "source": [
        "# === CONFIG: checkpoint paths & model-ctor lambdas \n",
        "# RERUN-AFTER-RESTART\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "# Use project-local data and models dirs defined earlier\n",
        "BREAST_DIR = DATA_DIR / \"breast_cancer\"\n",
        "CAL_DIR    = DATA_DIR / \"california_housing\"\n",
        "\n",
        "def latest_ckpt(pattern: str) -> Path:\n",
        "    \"\"\"Pick the most recently modified checkpoint matching a pattern.\"\"\"\n",
        "    candidates = sorted(Path(MODELS_DIR).glob(pattern))\n",
        "    assert candidates, f\"No checkpoints matching pattern: {pattern}\"\n",
        "    # choose by modification time\n",
        "    return max(candidates, key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "# Automatically pick the latest baseline checkpoints \n",
        "CLF_CKPT = latest_ckpt(\"clf_breast_cancer_baseline_*_best.pt\")\n",
        "REG_CKPT = latest_ckpt(\"reg_california_baseline_*_best.pt\")\n",
        "\n",
        "# Infer input dims from saved arrays\n",
        "n_in_clf = np.load(BREAST_DIR / \"X_train.npy\").shape[1]\n",
        "n_in_reg = np.load(CAL_DIR    / \"X_train.npy\").shape[1]\n",
        "\n",
        "# Recreate model-ctor lambdas (match the baseline architectures you trained)\n",
        "clf_ctor = lambda: FFNN_Classifier(n_in=n_in_clf, hidden=[64,64,32], n_out=2, p_drop=0.1)\n",
        "reg_ctor = lambda: FFNN_Regression(n_in=n_in_reg, hidden=[128,64,32], p_drop=0.1)\n",
        "\n",
        "print(\"CLF_CKPT:\", CLF_CKPT)\n",
        "print(\"REG_CKPT:\", REG_CKPT)\n",
        "\n",
        "# Inspect linear layers so we know which seq_index to target for damage\n",
        "print(\"Classifier linear layers:\", summarize_linear_layers(clf_ctor()))\n",
        "print(\"Regression linear layers:\", summarize_linear_layers(reg_ctor()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWUd9KR5hJDN",
        "outputId": "e900a15f-3b16-4bd2-caa4-5f8f775ea836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repeat 0: ACC=0.9535, F1=0.9630\n",
            "Repeat 1: ACC=0.9419, F1=0.9550\n",
            "Repeat 2: ACC=0.9070, F1=0.9259\n",
            "Repeat 3: ACC=0.8837, F1=0.9057\n",
            "Repeat 4: ACC=0.8837, F1=0.9038\n",
            "Repeat 5: ACC=0.8721, F1=0.8991\n",
            "Logged to: c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_immediate_drop.csv\n"
          ]
        }
      ],
      "source": [
        "#rerun when needed\n",
        "# SANITY EXPERIMENT: classification, 20% neurons in first hidden, 5 repeats ===\n",
        "set_seed(42)\n",
        "\n",
        "# first Linear layer's seq index (from your summary, it's 0)\n",
        "FIRST_LINEAR = summarize_linear_layers(clone_from_checkpoint(clf_ctor, CLF_CKPT))[0][\"seq_index\"]\n",
        "\n",
        "rows_to_log = []\n",
        "res = eval_task(\n",
        "    model_ctor=clf_ctor,\n",
        "    ckpt_path=CLF_CKPT,\n",
        "    task=\"clf\",\n",
        "    data_dir=BREAST_DIR,            # ← use local data dir\n",
        "    damage_fn=damage_neurons_in_layer,\n",
        "    repeats=5,                      # progressive (cumulative) damage\n",
        "    layer_lin_seq_index=FIRST_LINEAR,\n",
        "    pct_neurons=0.20                # 20% neurons\n",
        ")\n",
        "\n",
        "for step in res:\n",
        "    r = step[\"repeat\"]; m = step[\"metrics\"]\n",
        "    print(f\"Repeat {r}: ACC={m['accuracy']:.4f}, F1={m['f1']:.4f}\")\n",
        "    rows_to_log.append({\n",
        "        \"timestamp\": timestamp(),\n",
        "        \"phase\": \"damage_immediate\",\n",
        "        \"dataset\": \"breast_cancer\",\n",
        "        \"task\": \"clf\",\n",
        "        \"damage_type\": \"neurons\",\n",
        "        \"layer_seq_index\": FIRST_LINEAR,\n",
        "        \"pct\": 0.20,\n",
        "        \"repeat\": r,\n",
        "        \"test_accuracy\": m[\"accuracy\"],\n",
        "        \"test_f1\": m[\"f1\"]\n",
        "    })\n",
        "\n",
        "csv_path = save_experiment_log(rows_to_log, \"damage_immediate_drop.csv\")\n",
        "print(\"Logged to:\", csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Go_3K0XhoMJ",
        "outputId": "957124f5-b02c-4c19-e2b9-b6fd0ac7d72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log path exists: True | path: c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_immediate_drop.csv\n",
            "Last 8 rows:\n",
            "         timestamp             phase        dataset task damage_type  \\\n",
            "0  20250813-104930  damage_immediate  breast_cancer  clf     neurons   \n",
            "1  20250813-104930  damage_immediate  breast_cancer  clf     neurons   \n",
            "2  20250813-104930  damage_immediate  breast_cancer  clf     neurons   \n",
            "3  20250813-104930  damage_immediate  breast_cancer  clf     neurons   \n",
            "4  20250813-104930  damage_immediate  breast_cancer  clf     neurons   \n",
            "5  20250813-104930  damage_immediate  breast_cancer  clf     neurons   \n",
            "\n",
            "   layer_seq_index  pct  repeat  test_accuracy   test_f1  \n",
            "0                0  0.2       0       0.953488  0.962963  \n",
            "1                0  0.2       1       0.941860  0.954955  \n",
            "2                0  0.2       2       0.906977  0.925926  \n",
            "3                0  0.2       3       0.883721  0.905660  \n",
            "4                0  0.2       4       0.883721  0.903846  \n",
            "5                0  0.2       5       0.872093  0.899083  \n"
          ]
        }
      ],
      "source": [
        "# View damage log \n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "csv = Path(RESULTS_DIR) / \"damage_immediate_drop.csv\"\n",
        "print(\"Log path exists:\", csv.exists(), \"| path:\", csv)\n",
        "df = pd.read_csv(csv)\n",
        "print(\"Last 8 rows:\")\n",
        "print(df.tail(8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHo946-uiHV_",
        "outputId": "7f6fca40-179c-461a-f09a-340b8c9c769c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repeat 0: MAE=0.3749, RMSE=0.5373\n",
            "Repeat 1: MAE=0.5098, RMSE=0.7588\n",
            "Repeat 2: MAE=0.5256, RMSE=0.7507\n",
            "Repeat 3: MAE=0.5723, RMSE=0.8086\n",
            "Repeat 4: MAE=0.5954, RMSE=0.8313\n",
            "Repeat 5: MAE=0.6137, RMSE=0.9004\n",
            "Logged to: c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_immediate_drop.csv\n"
          ]
        }
      ],
      "source": [
        "# === SANITY: regression, 20% neurons in first hidden, 5 repeats \n",
        "set_seed(42)\n",
        "\n",
        "FIRST_LINEAR_REG = summarize_linear_layers(clone_from_checkpoint(reg_ctor, REG_CKPT))[0][\"seq_index\"]\n",
        "\n",
        "rows_to_log = []\n",
        "res = eval_task(\n",
        "    model_ctor=reg_ctor,\n",
        "    ckpt_path=REG_CKPT,\n",
        "    task=\"reg\",\n",
        "    data_dir=CAL_DIR,                 # ← use local data dir\n",
        "    damage_fn=damage_neurons_in_layer,\n",
        "    repeats=5,\n",
        "    layer_lin_seq_index=FIRST_LINEAR_REG,\n",
        "    pct_neurons=0.20\n",
        ")\n",
        "\n",
        "for step in res:\n",
        "    r = step[\"repeat\"]; m = step[\"metrics\"]\n",
        "    print(f\"Repeat {r}: MAE={m['mae']:.4f}, RMSE={m['rmse']:.4f}\")\n",
        "    rows_to_log.append({\n",
        "        \"timestamp\": timestamp(),\n",
        "        \"phase\": \"damage_immediate\",\n",
        "        \"dataset\": \"california_housing\",\n",
        "        \"task\": \"reg\",\n",
        "        \"damage_type\": \"neurons\",\n",
        "        \"layer_seq_index\": FIRST_LINEAR_REG,\n",
        "        \"pct\": 0.20,\n",
        "        \"repeat\": r,\n",
        "        \"test_mae\": m[\"mae\"],\n",
        "        \"test_rmse\": m[\"rmse\"]\n",
        "    })\n",
        "\n",
        "csv_path = save_experiment_log(rows_to_log, \"damage_immediate_drop.csv\")\n",
        "print(\"Logged to:\", csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BbFz8O9Bildr"
      },
      "outputs": [],
      "source": [
        "# === 4.4 EXPERIMENT RUNNER (logs tidy rows for each repeat) ===\n",
        "# Tag: RERUN-AFTER-RESTART\n",
        "\n",
        "def layer_seq_indices(model_ctor):\n",
        "    m = model_ctor().to(DEVICE)\n",
        "    return [d[\"seq_index\"] for d in summarize_linear_layers(m)]\n",
        "\n",
        "def run_damage_experiment(\n",
        "    model_ctor, ckpt_path, task, data_dir,\n",
        "    layer_seq_index, pct, repeats_list,\n",
        "    damage_type=\"neurons\", weight_mode=\"random\",\n",
        "    rng_seed=12345, csv_name=\"damage_immediate_drop.csv\"\n",
        "):\n",
        "    \"\"\"\n",
        "    For each repeats in repeats_list:\n",
        "      - reload clean checkpoint\n",
        "      - apply progressive damage (repeats times) on given layer\n",
        "      - evaluate after each repeat\n",
        "      - log baseline + each step, with deltas vs baseline\n",
        "    \"\"\"\n",
        "    assert damage_type in (\"neurons\",\"weights\")\n",
        "    rows = []\n",
        "    for repeats in repeats_list:\n",
        "        if damage_type == \"neurons\":\n",
        "            res = eval_task(\n",
        "                model_ctor=model_ctor, ckpt_path=ckpt_path, task=task, data_dir=data_dir,\n",
        "                damage_fn=damage_neurons_in_layer, repeats=repeats,\n",
        "                layer_lin_seq_index=layer_seq_index, pct_neurons=pct\n",
        "            )\n",
        "        else:\n",
        "            res = eval_task(\n",
        "                model_ctor=model_ctor, ckpt_path=ckpt_path, task=task, data_dir=data_dir,\n",
        "                damage_fn=damage_weights_in_layer, repeats=repeats,\n",
        "                layer_lin_seq_index=layer_seq_index, pct_weights=pct, mode=weight_mode\n",
        "            )\n",
        "\n",
        "        base = res[0][\"metrics\"]\n",
        "        for step in res:\n",
        "            r = step[\"repeat\"]; m = step[\"metrics\"]\n",
        "            row = {\n",
        "                \"timestamp\": timestamp(),\n",
        "                \"phase\": \"damage_immediate\",\n",
        "                \"task\": task,\n",
        "                \"damage_type\": damage_type,\n",
        "                \"layer_seq_index\": int(layer_seq_index),\n",
        "                \"pct\": float(pct),\n",
        "                \"repeats_total\": int(repeats),\n",
        "                \"repeat_eval\": int(r),\n",
        "                \"ckpt\": str(ckpt_path),\n",
        "            }\n",
        "            if task == \"clf\":\n",
        "                row.update({\n",
        "                    \"metric\": \"accuracy\",\n",
        "                    \"baseline_metric\": float(base[\"accuracy\"]),\n",
        "                    \"value\": float(m[\"accuracy\"]),\n",
        "                    \"delta_from_baseline\": float(base[\"accuracy\"] - m[\"accuracy\"]),\n",
        "                    \"f1\": float(m[\"f1\"]),\n",
        "                })\n",
        "            else:\n",
        "                row.update({\n",
        "                    \"metric\": \"rmse\",\n",
        "                    \"baseline_metric\": float(base[\"rmse\"]),\n",
        "                    \"value\": float(m[\"rmse\"]),\n",
        "                    \"delta_from_baseline\": float(m[\"rmse\"] - base[\"rmse\"]),\n",
        "                    \"mae\": float(m[\"mae\"]),\n",
        "                })\n",
        "            rows.append(row)\n",
        "\n",
        "    for row in rows:\n",
        "        log_result(row, csv_name=csv_name)\n",
        "    print(f\"Logged {len(rows)} rows to {RESULTS_DIR / csv_name}\")\n",
        "    return rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sWmZ8FHjDxh",
        "outputId": "10614aa4-8364-4cb4-c038-bcc4f4503276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged 6 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_immediate_drop.csv\n",
            "          timestamp             phase dataset task damage_type  \\\n",
            "12  20250813-105456  damage_immediate     NaN  clf     neurons   \n",
            "13  20250813-105456  damage_immediate     NaN  clf     neurons   \n",
            "14  20250813-105456  damage_immediate     NaN  clf     neurons   \n",
            "15  20250813-105456  damage_immediate     NaN  clf     neurons   \n",
            "16  20250813-105456  damage_immediate     NaN  clf     neurons   \n",
            "17  20250813-105456  damage_immediate     NaN  clf     neurons   \n",
            "\n",
            "    layer_seq_index  pct  repeat  test_accuracy  test_f1  test_mae  test_rmse  \\\n",
            "12                0  0.2     NaN            NaN      NaN       NaN        NaN   \n",
            "13                0  0.2     NaN            NaN      NaN       NaN        NaN   \n",
            "14                0  0.2     NaN            NaN      NaN       NaN        NaN   \n",
            "15                0  0.2     NaN            NaN      NaN       NaN        NaN   \n",
            "16                0  0.2     NaN            NaN      NaN       NaN        NaN   \n",
            "17                0  0.2     NaN            NaN      NaN       NaN        NaN   \n",
            "\n",
            "    repeats_total  repeat_eval  \\\n",
            "12            5.0          0.0   \n",
            "13            5.0          1.0   \n",
            "14            5.0          2.0   \n",
            "15            5.0          3.0   \n",
            "16            5.0          4.0   \n",
            "17            5.0          5.0   \n",
            "\n",
            "                                                 ckpt    metric  \\\n",
            "12  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "13  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "14  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "15  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "16  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "17  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "\n",
            "    baseline_metric     value  delta_from_baseline        f1  \n",
            "12         0.953488  0.953488             0.000000  0.962963  \n",
            "13         0.953488  0.941860             0.011628  0.954955  \n",
            "14         0.953488  0.906977             0.046512  0.925926  \n",
            "15         0.953488  0.883721             0.069767  0.905660  \n",
            "16         0.953488  0.883721             0.069767  0.903846  \n",
            "17         0.953488  0.872093             0.081395  0.899083  \n"
          ]
        }
      ],
      "source": [
        "# CLASSIFICATION: first hidden layer (seq 0), 20% neurons, repeats = [5]\n",
        "first_lin_clf = layer_seq_indices(clf_ctor)[0]  # should be 0\n",
        "_ = run_damage_experiment(\n",
        "    model_ctor=clf_ctor, ckpt_path=CLF_CKPT, task=\"clf\", data_dir=BREAST_DIR,\n",
        "    layer_seq_index=first_lin_clf, pct=0.20, repeats_list=[5],\n",
        "    damage_type=\"neurons\", csv_name=\"damage_immediate_drop.csv\"\n",
        ")\n",
        "\n",
        "# quick peek\n",
        "import pandas as pd\n",
        "df = pd.read_csv(RESULTS_DIR / \"damage_immediate_drop.csv\")\n",
        "print(df.tail(6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jf5EV8NVjZAH"
      },
      "outputs": [],
      "source": [
        "# === 4.4 EXPERIMENT RUNNER (with dataset_name + selectable CSV) — VS Code version ===\n",
        "# Tag: RERUN-AFTER-RESTART\n",
        "\n",
        "def run_damage_experiment(\n",
        "    model_ctor, ckpt_path, task, data_dir,\n",
        "    layer_seq_index, pct, repeats_list,\n",
        "    damage_type=\"neurons\", weight_mode=\"random\",\n",
        "    rng_seed=12345, csv_name=\"damage_runs.csv\",\n",
        "    dataset_name=None\n",
        "):\n",
        "    \"\"\"\n",
        "    For each 'repeats' in repeats_list:\n",
        "      - reload clean checkpoint\n",
        "      - apply progressive damage (repeats times) on given layer\n",
        "      - evaluate after each repeat\n",
        "      - log baseline + each step with deltas\n",
        "    \"\"\"\n",
        "    assert damage_type in (\"neurons\", \"weights\")\n",
        "    rows = []\n",
        "    for repeats in repeats_list:\n",
        "        if damage_type == \"neurons\":\n",
        "            res = eval_task(\n",
        "                model_ctor=model_ctor, ckpt_path=ckpt_path, task=task, data_dir=data_dir,\n",
        "                damage_fn=damage_neurons_in_layer, repeats=repeats,\n",
        "                layer_lin_seq_index=layer_seq_index, pct_neurons=pct\n",
        "            )\n",
        "        else:\n",
        "            res = eval_task(\n",
        "                model_ctor=model_ctor, ckpt_path=ckpt_path, task=task, data_dir=data_dir,\n",
        "                damage_fn=damage_weights_in_layer, repeats=repeats,\n",
        "                layer_lin_seq_index=layer_seq_index, pct_weights=pct, mode=weight_mode\n",
        "            )\n",
        "\n",
        "        base = res[0][\"metrics\"]\n",
        "        for step in res:\n",
        "            r = step[\"repeat\"]; m = step[\"metrics\"]\n",
        "            row = {\n",
        "                \"timestamp\": timestamp(),\n",
        "                \"phase\": \"damage_immediate\",\n",
        "                \"dataset\": dataset_name,\n",
        "                \"task\": task,\n",
        "                \"damage_type\": damage_type,\n",
        "                \"layer_seq_index\": int(layer_seq_index),\n",
        "                \"pct\": float(pct),\n",
        "                \"repeats_total\": int(repeats),\n",
        "                \"repeat_eval\": int(r),\n",
        "                \"ckpt\": str(ckpt_path)\n",
        "            }\n",
        "            if task == \"clf\":\n",
        "                row.update({\n",
        "                    \"metric\": \"accuracy\",\n",
        "                    \"baseline_metric\": float(base[\"accuracy\"]),\n",
        "                    \"value\": float(m[\"accuracy\"]),\n",
        "                    \"delta_from_baseline\": float(base[\"accuracy\"] - m[\"accuracy\"]),\n",
        "                    \"f1\": float(m[\"f1\"])\n",
        "                })\n",
        "            else:\n",
        "                row.update({\n",
        "                    \"metric\": \"rmse\",\n",
        "                    \"baseline_metric\": float(base[\"rmse\"]),\n",
        "                    \"value\": float(m[\"rmse\"]),\n",
        "                    \"delta_from_baseline\": float(m[\"rmse\"] - base[\"rmse\"]),\n",
        "                    \"mae\": float(m[\"mae\"])\n",
        "                })\n",
        "            rows.append(row)\n",
        "\n",
        "    for row in rows:\n",
        "        log_result(row, csv_name=csv_name)\n",
        "    print(f\"Logged {len(rows)} rows to {RESULTS_DIR / csv_name}\")\n",
        "    return rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf1iESRgkUfr",
        "outputId": "b0c7cd0b-1f91-4b42-c008-553e24a1aa69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged 6 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_runs.csv\n",
            "         timestamp             phase        dataset task damage_type  \\\n",
            "0  20250813-110039  damage_immediate  breast_cancer  clf     neurons   \n",
            "1  20250813-110039  damage_immediate  breast_cancer  clf     neurons   \n",
            "2  20250813-110039  damage_immediate  breast_cancer  clf     neurons   \n",
            "3  20250813-110039  damage_immediate  breast_cancer  clf     neurons   \n",
            "4  20250813-110039  damage_immediate  breast_cancer  clf     neurons   \n",
            "5  20250813-110039  damage_immediate  breast_cancer  clf     neurons   \n",
            "\n",
            "   layer_seq_index  pct  repeats_total  repeat_eval  \\\n",
            "0                0  0.2              5            0   \n",
            "1                0  0.2              5            1   \n",
            "2                0  0.2              5            2   \n",
            "3                0  0.2              5            3   \n",
            "4                0  0.2              5            4   \n",
            "5                0  0.2              5            5   \n",
            "\n",
            "                                                ckpt    metric  \\\n",
            "0  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "1  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "2  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "3  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "4  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "5  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "\n",
            "   baseline_metric     value  delta_from_baseline        f1  \n",
            "0         0.953488  0.953488             0.000000  0.962963  \n",
            "1         0.953488  0.941860             0.011628  0.954955  \n",
            "2         0.953488  0.906977             0.046512  0.925926  \n",
            "3         0.953488  0.883721             0.069767  0.905660  \n",
            "4         0.953488  0.883721             0.069767  0.903846  \n",
            "5         0.953488  0.872093             0.081395  0.899083  \n"
          ]
        }
      ],
      "source": [
        "# CLASSIFICATION: first hidden layer (seq 0), 20% neurons, repeats=[5]\n",
        "#run on demand\n",
        "first_lin_clf = layer_seq_indices(clf_ctor)[0]  # seq index 0\n",
        "_ = run_damage_experiment(\n",
        "    model_ctor=clf_ctor, ckpt_path=CLF_CKPT, task=\"clf\", data_dir=BREAST_DIR,\n",
        "    layer_seq_index=first_lin_clf, pct=0.20, repeats_list=[5],\n",
        "    damage_type=\"neurons\", csv_name=\"damage_runs.csv\",\n",
        "    dataset_name=\"breast_cancer\"\n",
        ")\n",
        "\n",
        "# quick peek of the appended rows\n",
        "import pandas as pd\n",
        "df_new = pd.read_csv(RESULTS_DIR / \"damage_runs.csv\")\n",
        "print(df_new.tail(6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o90w_UxTkhhf",
        "outputId": "26e3fa7b-a91a-40b3-b344-705a02029eef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged 17 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_runs.csv\n",
            "Logged 17 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_runs.csv\n",
            "          timestamp             phase        dataset task damage_type  \\\n",
            "28  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "29  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "30  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "31  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "32  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "33  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "34  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "35  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "36  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "37  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "38  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "39  20250813-110315  damage_immediate  breast_cancer  clf     neurons   \n",
            "\n",
            "    layer_seq_index  pct  repeats_total  repeat_eval  \\\n",
            "28                0  0.4              5            5   \n",
            "29                0  0.4             10            0   \n",
            "30                0  0.4             10            1   \n",
            "31                0  0.4             10            2   \n",
            "32                0  0.4             10            3   \n",
            "33                0  0.4             10            4   \n",
            "34                0  0.4             10            5   \n",
            "35                0  0.4             10            6   \n",
            "36                0  0.4             10            7   \n",
            "37                0  0.4             10            8   \n",
            "38                0  0.4             10            9   \n",
            "39                0  0.4             10           10   \n",
            "\n",
            "                                                 ckpt    metric  \\\n",
            "28  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "29  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "30  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "31  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "32  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "33  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "34  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "35  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "36  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "37  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "38  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "39  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "\n",
            "    baseline_metric     value  delta_from_baseline        f1  \n",
            "28         0.953488  0.790698             0.162791  0.826923  \n",
            "29         0.953488  0.953488             0.000000  0.962963  \n",
            "30         0.953488  0.930233             0.023256  0.947368  \n",
            "31         0.953488  0.895349             0.058140  0.923077  \n",
            "32         0.953488  0.906977             0.046512  0.931034  \n",
            "33         0.953488  0.802326             0.151163  0.838095  \n",
            "34         0.953488  0.790698             0.162791  0.826923  \n",
            "35         0.953488  0.372093             0.581395  0.000000  \n",
            "36         0.953488  0.372093             0.581395  0.000000  \n",
            "37         0.953488  0.372093             0.581395  0.000000  \n",
            "38         0.953488  0.372093             0.581395  0.000000  \n",
            "39         0.953488  0.372093             0.581395  0.000000  \n"
          ]
        }
      ],
      "source": [
        "#  SMALL BATCH: clf · first hidden · neurons · 20% & 40% · repeats [5, 10]\n",
        "set_seed(42)\n",
        "\n",
        "first_lin_clf = layer_seq_indices(clf_ctor)[0]  # seq index 0\n",
        "\n",
        "# 20% neurons, repeats 5 and 10\n",
        "_ = run_damage_experiment(\n",
        "    model_ctor=clf_ctor, ckpt_path=CLF_CKPT, task=\"clf\", data_dir=BREAST_DIR,\n",
        "    layer_seq_index=first_lin_clf, pct=0.20, repeats_list=[5, 10],\n",
        "    damage_type=\"neurons\", csv_name=\"damage_runs.csv\", dataset_name=\"breast_cancer\"\n",
        ")\n",
        "\n",
        "# 40% neurons, repeats 5 and 10\n",
        "_ = run_damage_experiment(\n",
        "    model_ctor=clf_ctor, ckpt_path=CLF_CKPT, task=\"clf\", data_dir=BREAST_DIR,\n",
        "    layer_seq_index=first_lin_clf, pct=0.40, repeats_list=[5, 10],\n",
        "    damage_type=\"neurons\", csv_name=\"damage_runs.csv\", dataset_name=\"breast_cancer\"\n",
        ")\n",
        "\n",
        "# quick peek of just these rows\n",
        "import pandas as pd\n",
        "df = pd.read_csv(RESULTS_DIR / \"damage_runs.csv\")\n",
        "mask = (\n",
        "    (df[\"dataset\"] == \"breast_cancer\") &\n",
        "    (df[\"task\"] == \"clf\") &\n",
        "    (df[\"damage_type\"] == \"neurons\") &\n",
        "    (df[\"layer_seq_index\"] == first_lin_clf) &\n",
        "    (df[\"pct\"].isin([0.2, 0.4])) &\n",
        "    (df[\"repeats_total\"].isin([5, 10]))\n",
        ")\n",
        "print(df[mask].tail(12))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWWhXjJWk3tx",
        "outputId": "0ebfddce-d86c-4b16-8a37-f23902448716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged 17 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_runs.csv\n",
            "Logged 17 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_runs.csv\n",
            "          timestamp             phase        dataset task damage_type  \\\n",
            "62  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "63  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "64  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "65  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "66  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "67  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "68  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "69  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "70  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "71  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "72  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "73  20250813-110450  damage_immediate  breast_cancer  clf     neurons   \n",
            "\n",
            "    layer_seq_index  pct  repeats_total  repeat_eval  \\\n",
            "62                9  0.4              5            5   \n",
            "63                9  0.4             10            0   \n",
            "64                9  0.4             10            1   \n",
            "65                9  0.4             10            2   \n",
            "66                9  0.4             10            3   \n",
            "67                9  0.4             10            4   \n",
            "68                9  0.4             10            5   \n",
            "69                9  0.4             10            6   \n",
            "70                9  0.4             10            7   \n",
            "71                9  0.4             10            8   \n",
            "72                9  0.4             10            9   \n",
            "73                9  0.4             10           10   \n",
            "\n",
            "                                                 ckpt    metric  \\\n",
            "62  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "63  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "64  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "65  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "66  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "67  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "68  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "69  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "70  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "71  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "72  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "73  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\clf...  accuracy   \n",
            "\n",
            "    baseline_metric     value  delta_from_baseline        f1  \n",
            "62         0.953488  0.372093             0.581395  0.000000  \n",
            "63         0.953488  0.953488             0.000000  0.962963  \n",
            "64         0.953488  0.965116            -0.011628  0.972973  \n",
            "65         0.953488  0.372093             0.581395  0.000000  \n",
            "66         0.953488  0.372093             0.581395  0.000000  \n",
            "67         0.953488  0.372093             0.581395  0.000000  \n",
            "68         0.953488  0.372093             0.581395  0.000000  \n",
            "69         0.953488  0.372093             0.581395  0.000000  \n",
            "70         0.953488  0.372093             0.581395  0.000000  \n",
            "71         0.953488  0.372093             0.581395  0.000000  \n",
            "72         0.953488  0.372093             0.581395  0.000000  \n",
            "73         0.953488  0.372093             0.581395  0.000000  \n"
          ]
        }
      ],
      "source": [
        "# clf · OUTPUT layer · neurons · 20% & 40% · repeats [5, 10]\n",
        "set_seed(42)\n",
        "\n",
        "last_lin_clf = layer_seq_indices(clf_ctor)[-1]  # seq index of output Linear\n",
        "\n",
        "# 20% neurons, repeats 5 and 10\n",
        "_ = run_damage_experiment(\n",
        "    model_ctor=clf_ctor, ckpt_path=CLF_CKPT, task=\"clf\", data_dir=BREAST_DIR,\n",
        "    layer_seq_index=last_lin_clf, pct=0.20, repeats_list=[5, 10],\n",
        "    damage_type=\"neurons\", csv_name=\"damage_runs.csv\", dataset_name=\"breast_cancer\"\n",
        ")\n",
        "\n",
        "# 40% neurons, repeats 5 and 10\n",
        "_ = run_damage_experiment(\n",
        "    model_ctor=clf_ctor, ckpt_path=CLF_CKPT, task=\"clf\", data_dir=BREAST_DIR,\n",
        "    layer_seq_index=last_lin_clf, pct=0.40, repeats_list=[5, 10],\n",
        "    damage_type=\"neurons\", csv_name=\"damage_runs.csv\", dataset_name=\"breast_cancer\"\n",
        ")\n",
        "\n",
        "# Quick peek of these specific rows\n",
        "import pandas as pd\n",
        "df = pd.read_csv(RESULTS_DIR / \"damage_runs.csv\")\n",
        "mask = (\n",
        "    (df[\"dataset\"] == \"breast_cancer\") &\n",
        "    (df[\"task\"] == \"clf\") &\n",
        "    (df[\"damage_type\"] == \"neurons\") &\n",
        "    (df[\"layer_seq_index\"] == last_lin_clf) &\n",
        "    (df[\"pct\"].isin([0.2, 0.4])) &\n",
        "    (df[\"repeats_total\"].isin([5, 10]))\n",
        ")\n",
        "print(df[mask].tail(12))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmY7a62TlROD",
        "outputId": "9470d3cc-95ce-4817-9532-9b69df201670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged 17 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_runs.csv\n",
            "Logged 17 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\damage_runs.csv\n",
            "           timestamp             phase             dataset task damage_type  \\\n",
            "96   20250813-110723  damage_immediate  california_housing  reg     neurons   \n",
            "97   20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "98   20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "99   20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "100  20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "101  20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "102  20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "103  20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "104  20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "105  20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "106  20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "107  20250813-110724  damage_immediate  california_housing  reg     neurons   \n",
            "\n",
            "     layer_seq_index  pct  repeats_total  repeat_eval  \\\n",
            "96                 0  0.4              5            5   \n",
            "97                 0  0.4             10            0   \n",
            "98                 0  0.4             10            1   \n",
            "99                 0  0.4             10            2   \n",
            "100                0  0.4             10            3   \n",
            "101                0  0.4             10            4   \n",
            "102                0  0.4             10            5   \n",
            "103                0  0.4             10            6   \n",
            "104                0  0.4             10            7   \n",
            "105                0  0.4             10            8   \n",
            "106                0  0.4             10            9   \n",
            "107                0  0.4             10           10   \n",
            "\n",
            "                                                  ckpt metric  \\\n",
            "96   c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "97   c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "98   c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "99   c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "100  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "101  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "102  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "103  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "104  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "105  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "106  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "107  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\reg...   rmse   \n",
            "\n",
            "     baseline_metric     value  delta_from_baseline  f1       mae  \n",
            "96          0.537336  1.257674             0.720338 NaN  0.905047  \n",
            "97          0.537336  0.537336             0.000000 NaN  0.374850  \n",
            "98          0.537336  0.644867             0.107531 NaN  0.482532  \n",
            "99          0.537336  0.859450             0.322114 NaN  0.591337  \n",
            "100         0.537336  1.071479             0.534144 NaN  0.765762  \n",
            "101         0.537336  1.176146             0.638811 NaN  0.840240  \n",
            "102         0.537336  1.257674             0.720338 NaN  0.905047  \n",
            "103         0.537336  1.247198             0.709863 NaN  0.899043  \n",
            "104         0.537336  1.239897             0.702562 NaN  0.901800  \n",
            "105         0.537336  1.253172             0.715837 NaN  0.913375  \n",
            "106         0.537336  1.253172             0.715837 NaN  0.913375  \n",
            "107         0.537336  1.253172             0.715837 NaN  0.913375  \n"
          ]
        }
      ],
      "source": [
        "# SMALL BATCH: reg · first hidden · neurons · 20% & 40% · repeats [5, 10]\n",
        "set_seed(42)\n",
        "\n",
        "first_lin_reg = layer_seq_indices(reg_ctor)[0]  # seq index 0\n",
        "\n",
        "# 20% neurons, repeats 5 and 10\n",
        "_ = run_damage_experiment(\n",
        "    model_ctor=reg_ctor, ckpt_path=REG_CKPT, task=\"reg\", data_dir=CAL_DIR,\n",
        "    layer_seq_index=first_lin_reg, pct=0.20, repeats_list=[5, 10],\n",
        "    damage_type=\"neurons\", csv_name=\"damage_runs.csv\", dataset_name=\"california_housing\"\n",
        ")\n",
        "\n",
        "# 40% neurons, repeats 5 and 10\n",
        "_ = run_damage_experiment(\n",
        "    model_ctor=reg_ctor, ckpt_path=REG_CKPT, task=\"reg\", data_dir=CAL_DIR,\n",
        "    layer_seq_index=first_lin_reg, pct=0.40, repeats_list=[5, 10],\n",
        "    damage_type=\"neurons\", csv_name=\"damage_runs.csv\", dataset_name=\"california_housing\"\n",
        ")\n",
        "\n",
        "# Quick peek of just these rows\n",
        "import pandas as pd\n",
        "df = pd.read_csv(RESULTS_DIR / \"damage_runs.csv\")\n",
        "mask = (\n",
        "    (df[\"dataset\"] == \"california_housing\") &\n",
        "    (df[\"task\"] == \"reg\") &\n",
        "    (df[\"damage_type\"] == \"neurons\") &\n",
        "    (df[\"layer_seq_index\"] == first_lin_reg) &\n",
        "    (df[\"pct\"].isin([0.2, 0.4])) &\n",
        "    (df[\"repeats_total\"].isin([5, 10]))\n",
        ")\n",
        "print(df[mask].tail(12))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "s5smUJZOlz40"
      },
      "outputs": [],
      "source": [
        "#  Healing scaffolding (gradient masks + masked damage) \n",
        "#rerun\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Reuse: get_linear_layers, summarize_linear_layers, clone_from_checkpoint,\n",
        "# make_loaders, evaluate_model, set_seed, DEVICE, MODELS_DIR already defined.\n",
        "\n",
        "def _ensure_mask(t, fill=1.0):\n",
        "    \"\"\"Create a float mask same shape as tensor t, filled with fill (1.0 = trainable, 0.0 = freeze).\"\"\"\n",
        "    return torch.full_like(t, float(fill))\n",
        "\n",
        "def combine_mask_(base_mask: torch.Tensor, new_mask: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Combine two masks in-place using AND semantics for freezing:\n",
        "    final_keep = base_keep * new_keep\n",
        "    \"\"\"\n",
        "    base_mask.mul_(new_mask)\n",
        "    return base_mask\n",
        "\n",
        "def register_grad_mask_hooks(mask_dict):\n",
        "    \"\"\"\n",
        "    Given {param_tensor: mask_tensor}, register a backward hook that multiplies incoming gradients by the mask.\n",
        "    Keep the returned handles alive; call handle.remove() when done.\n",
        "    \"\"\"\n",
        "    hooks = []\n",
        "    for p, m in mask_dict.items():\n",
        "        mm = m.to(p.device).to(p.dtype)\n",
        "        h = p.register_hook(lambda g, _mm=mm: g * _mm)\n",
        "        hooks.append(h)\n",
        "    return hooks\n",
        "\n",
        "def init_full_keep_masks_for_model(model: nn.Module):\n",
        "    \"\"\"\n",
        "    Build an initial mask dict of ones (keep/train) for each Linear weight/bias.\n",
        "    We will AND (multiply) zeros into these masks as we damage more.\n",
        "    \"\"\"\n",
        "    mask_dict = {}\n",
        "    for _, m in model.named_modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            mask_dict[m.weight] = _ensure_mask(m.weight, fill=1.0)\n",
        "            if m.bias is not None:\n",
        "                mask_dict[m.bias] = _ensure_mask(m.bias, fill=1.0)\n",
        "    return mask_dict\n",
        "\n",
        "def damage_neurons_in_layer_with_masks(model: nn.Module, layer_lin_seq_index: int, pct_neurons: float,\n",
        "                                       rng: np.random.Generator, mask_dict=None):\n",
        "    \"\"\"\n",
        "    Same as damage_neurons_in_layer, but also updates a mask_dict so damaged entries are frozen.\n",
        "    - Zero rows in target Linear weight + corresponding bias entries.\n",
        "    - Zero columns in the next Linear weight (outgoing).\n",
        "    Returns: (damaged_neuron_indices, mask_dict)\n",
        "    \"\"\"\n",
        "    linear_layers = get_linear_layers(model)\n",
        "    target_pos = None\n",
        "    for k, (seq_i, lin) in enumerate(linear_layers):\n",
        "        if seq_i == layer_lin_seq_index:\n",
        "            target_pos = k\n",
        "            break\n",
        "    assert target_pos is not None, f\"No Linear layer at seq index {layer_lin_seq_index}\"\n",
        "    _, target_lin = linear_layers[target_pos]\n",
        "    next_lin = linear_layers[target_pos + 1][1] if (target_pos + 1) < len(linear_layers) else None\n",
        "\n",
        "    out_feats = target_lin.out_features\n",
        "    n_dmg = max(1, int(round(pct_neurons * out_feats)))\n",
        "    dmg_neurons = rng.choice(out_feats, size=n_dmg, replace=False)\n",
        "\n",
        "    if mask_dict is None:\n",
        "        mask_dict = init_full_keep_masks_for_model(model)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Zero rows in target weight + target bias at damaged neurons; mark them frozen (mask=0)\n",
        "        W = target_lin.weight  # [out, in]\n",
        "        W[dmg_neurons, :] = 0.0\n",
        "        maskW = mask_dict.get(W, _ensure_mask(W, 1.0)); maskW[dmg_neurons, :] = 0.0; mask_dict[W] = maskW\n",
        "\n",
        "        if target_lin.bias is not None:\n",
        "            b = target_lin.bias\n",
        "            b[dmg_neurons] = 0.0\n",
        "            maskb = mask_dict.get(b, _ensure_mask(b, 1.0)); maskb[dmg_neurons] = 0.0; mask_dict[b] = maskb\n",
        "\n",
        "        # Zero outgoing columns in next layer's weight; mark them frozen\n",
        "        if next_lin is not None:\n",
        "            Wn = next_lin.weight  # [next_out, next_in]\n",
        "            Wn[:, dmg_neurons] = 0.0\n",
        "            maskWn = mask_dict.get(Wn, _ensure_mask(Wn, 1.0)); maskWn[:, dmg_neurons] = 0.0; mask_dict[Wn] = maskWn\n",
        "\n",
        "    return dmg_neurons.tolist(), mask_dict\n",
        "\n",
        "def apply_progressive_neuron_damage_with_masks(model_ctor, ckpt_path, task, data_dir,\n",
        "                                               layer_lin_seq_index, pct_neurons, repeats, seed=12345):\n",
        "    \"\"\"\n",
        "    Load clean model, apply progressive neuron damage (repeats times),\n",
        "    accumulating both damage and masks.\n",
        "    Returns: model_damaged, mask_dict, train_loader, val_loader, test_loader, metrics_before, metrics_after\n",
        "    \"\"\"\n",
        "    if task == \"clf\":\n",
        "        train_loader, val_loader, test_loader, _ = make_loaders(data_dir, \"clf\", batch_size=256)\n",
        "    else:\n",
        "        train_loader, val_loader, test_loader, _ = make_loaders(data_dir, \"reg\", batch_size=512)\n",
        "\n",
        "    model = clone_from_checkpoint(model_ctor, ckpt_path)\n",
        "    metrics_before = evaluate_model(model, test_loader, task)\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    mask_dict = init_full_keep_masks_for_model(model)\n",
        "\n",
        "    for _ in range(repeats):\n",
        "        _, mask_dict = damage_neurons_in_layer_with_masks(\n",
        "            model, layer_lin_seq_index=layer_lin_seq_index, pct_neurons=pct_neurons, rng=rng, mask_dict=mask_dict\n",
        "        )\n",
        "\n",
        "    metrics_after = evaluate_model(model, test_loader, task)\n",
        "    return model, mask_dict, train_loader, val_loader, test_loader, metrics_before, metrics_after\n",
        "\n",
        "def healing_train_constrained(model, mask_dict, train_loader, val_loader, task,\n",
        "                              max_epochs=50, lr=1e-3, weight_decay=1e-4, patience=10, run_name=\"heal\"):\n",
        "    \"\"\"\n",
        "    Retrain while freezing masked entries (0=freeze). We enforce freezing by:\n",
        "      1) multiplying grads by mask (hook), AND\n",
        "      2) post-step: p.data *= mask  (prevents weight_decay/optimizer from moving frozen params)\n",
        "    Returns: best_path, history\n",
        "    \"\"\"\n",
        "    model = model.to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss() if task == \"clf\" else nn.MSELoss()\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "    # register grad-mask hooks\n",
        "    hooks = register_grad_mask_hooks(mask_dict)\n",
        "\n",
        "    history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_metric\": []}\n",
        "    best_val = float(\"inf\")\n",
        "    best_path = Path(MODELS_DIR) / f\"{run_name}_{timestamp()}_best.pt\"\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        model.train(); train_losses = []\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb if task == \"clf\" else yb)\n",
        "            loss.backward()\n",
        "\n",
        "            # standard optimizer step\n",
        "            opt.step()\n",
        "\n",
        "            # POST-STEP ENFORCEMENT: keep frozen entries at their masked values (0)\n",
        "            with torch.no_grad():\n",
        "                for p, m in mask_dict.items():\n",
        "                    p.data.mul_(m.to(p.device).to(p.dtype))\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "        train_loss = float(np.mean(train_losses)) if train_losses else 0.0\n",
        "\n",
        "        # validate\n",
        "        model.eval(); val_losses = []; y_true_list, y_pred_list = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "                out = model(xb)\n",
        "                vloss = criterion(out, yb if task == \"clf\" else yb)\n",
        "                val_losses.append(vloss.item())\n",
        "                if task == \"clf\":\n",
        "                    y_pred_list.append(out.argmax(dim=1).cpu().numpy()); y_true_list.append(yb.cpu().numpy())\n",
        "                else:\n",
        "                    y_pred_list.append(out.cpu().numpy().squeeze()); y_true_list.append(yb.cpu().numpy().squeeze())\n",
        "\n",
        "        val_loss = float(np.mean(val_losses)) if val_losses else 0.0\n",
        "        if task == \"clf\":\n",
        "            import numpy as _np\n",
        "            y_true = _np.concatenate(y_true_list); y_pred = _np.concatenate(y_pred_list)\n",
        "            from sklearn.metrics import accuracy_score as _acc\n",
        "            val_metric = float(_acc(y_true, y_pred))\n",
        "        else:\n",
        "            import numpy as _np, math as _math\n",
        "            from sklearn.metrics import mean_squared_error as _mse\n",
        "            y_true = _np.array(_np.concatenate([_np.atleast_1d(a) for a in y_true_list]))\n",
        "            y_pred = _np.array(_np.concatenate([_np.atleast_1d(a) for a in y_pred_list]))\n",
        "            val_metric = float(_math.sqrt(_mse(y_true, y_pred)))\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        history[\"epoch\"].append(epoch); history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss); history[\"val_metric\"].append(val_metric)\n",
        "\n",
        "        # save best by val_loss\n",
        "        if val_loss < best_val - 1e-8:\n",
        "            best_val = val_loss; epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), best_path); mark = \"*\"\n",
        "        else:\n",
        "            epochs_no_improve += 1; mark = \"\"\n",
        "        if epoch % 10 == 0 or mark == \"*\":\n",
        "            print(f\"[{run_name}] epoch {epoch:03d} | train {train_loss:.4f} | val {val_loss:.4f} | metric {val_metric:.4f} {mark}\")\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"[{run_name}] Early stopping at epoch {epoch}. Best val_loss={best_val:.4f}\")\n",
        "            break\n",
        "\n",
        "    # clean up hooks\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "    return best_path, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nlrjimSmjZt",
        "outputId": "909371e8-bfab-4678-cc41-29f31f51476b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASELINE: {'accuracy': 0.9534883720930233, 'f1': 0.9629629629629629}\n",
            "POST-DAMAGE: {'accuracy': 0.872093023255814, 'f1': 0.8990825688073395}\n"
          ]
        }
      ],
      "source": [
        "#rerun\n",
        "# create a damaged model + masks (clf, first hidden, 20%, 5 repeats)\n",
        "set_seed(42)\n",
        "\n",
        "first_lin_clf = layer_seq_indices(clf_ctor)[0]  # seq index 0\n",
        "\n",
        "damaged_model, mask_dict, train_loader, val_loader, test_loader, m_before, m_after = \\\n",
        "    apply_progressive_neuron_damage_with_masks(\n",
        "        model_ctor=clf_ctor,\n",
        "        ckpt_path=CLF_CKPT,\n",
        "        task=\"clf\",\n",
        "        data_dir=BREAST_DIR,          # ← local data dir\n",
        "        layer_lin_seq_index=first_lin_clf,\n",
        "        pct_neurons=0.20,\n",
        "        repeats=5,\n",
        "        seed=12345\n",
        "    )\n",
        "\n",
        "print(\"BASELINE:\", m_before)\n",
        "print(\"POST-DAMAGE:\", m_after)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ifyS2gm3mc",
        "outputId": "a38d5833-2afc-4014-9146-38acb1d6d2ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[heal_clf_firstHidden_p20_r5_short] epoch 001 | train 0.1583 | val 0.1570 | metric 0.9412 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 002 | train 0.1435 | val 0.1386 | metric 0.9529 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 003 | train 0.1475 | val 0.1244 | metric 0.9529 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 004 | train 0.1060 | val 0.1126 | metric 0.9647 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 005 | train 0.1099 | val 0.1030 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 006 | train 0.0790 | val 0.0950 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 007 | train 0.0938 | val 0.0895 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 008 | train 0.0886 | val 0.0849 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 009 | train 0.0716 | val 0.0820 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 010 | train 0.0671 | val 0.0788 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 011 | train 0.0817 | val 0.0766 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 012 | train 0.0675 | val 0.0754 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 013 | train 0.0651 | val 0.0747 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_short] epoch 014 | train 0.0744 | val 0.0741 | metric 0.9765 *\n",
            "SHORT HEAL (≈15 epochs) TEST: {'accuracy': 0.9302325581395349, 'f1': 0.9444444444444444}\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 001 | train 0.1274 | val 0.1551 | metric 0.9529 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 002 | train 0.1160 | val 0.1346 | metric 0.9529 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 003 | train 0.1370 | val 0.1195 | metric 0.9647 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 004 | train 0.1067 | val 0.1074 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 005 | train 0.1072 | val 0.0976 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 006 | train 0.0985 | val 0.0897 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 007 | train 0.0835 | val 0.0834 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 008 | train 0.0857 | val 0.0793 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 009 | train 0.0849 | val 0.0763 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 010 | train 0.0902 | val 0.0739 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 011 | train 0.0935 | val 0.0722 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 012 | train 0.0697 | val 0.0710 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 013 | train 0.0862 | val 0.0704 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 020 | train 0.0648 | val 0.0709 | metric 0.9765 \n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 021 | train 0.0636 | val 0.0701 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 022 | train 0.0711 | val 0.0694 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 023 | train 0.0502 | val 0.0692 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 024 | train 0.0601 | val 0.0690 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 025 | train 0.0658 | val 0.0687 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 026 | train 0.0719 | val 0.0686 | metric 0.9765 *\n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 030 | train 0.0699 | val 0.0700 | metric 0.9765 \n",
            "[heal_clf_firstHidden_p20_r5_long] epoch 040 | train 0.0480 | val 0.0731 | metric 0.9765 \n",
            "[heal_clf_firstHidden_p20_r5_long] Early stopping at epoch 46. Best val_loss=0.0686\n",
            "LONG HEAL (≈150 epochs) TEST: {'accuracy': 0.9651162790697675, 'f1': 0.9719626168224299}\n",
            "Logged 4 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\healing_runs.csv\n",
            "Short heal plots: c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_firstHidden_p20_r5_short_loss.png | c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_firstHidden_p20_r5_short_accuracy.png\n",
            "Long heal plots: c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_firstHidden_p20_r5_long_loss.png | c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_firstHidden_p20_r5_long_accuracy.png\n"
          ]
        }
      ],
      "source": [
        "#rerun\n",
        "# heal (short vs long), evaluate, save plots, and log\n",
        "\n",
        "# ---- SHORT HEAL (≈15 epochs) ----\n",
        "short_name = \"heal_clf_firstHidden_p20_r5_short\"\n",
        "best_short_path, hist_short = healing_train_constrained(\n",
        "    model=damaged_model,\n",
        "    mask_dict=mask_dict,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    task=\"clf\",\n",
        "    max_epochs=15,          # quick heal\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    patience=5,\n",
        "    run_name=short_name\n",
        ")\n",
        "\n",
        "# Load the best short-healed weights into a fresh model and evaluate on TEST\n",
        "m_short = clf_ctor().to(DEVICE)\n",
        "m_short.load_state_dict(torch.load(best_short_path, map_location=DEVICE))\n",
        "metrics_short = evaluate_model(m_short, test_loader, task=\"clf\")\n",
        "print(\"SHORT HEAL (≈15 epochs) TEST:\", metrics_short)\n",
        "\n",
        "# Plot short-heal curves\n",
        "fig_loss_s, fig_metric_s = plot_history(hist_short, short_name, task=\"clf\")\n",
        "\n",
        "# ---- LONG HEAL (≈150 epochs) ----\n",
        "# IMPORTANT: start from the same post-damage state again (not from the short-healed model)\n",
        "damaged_model2, mask_dict2, train_loader2, val_loader2, test_loader2, _, _ = \\\n",
        "    apply_progressive_neuron_damage_with_masks(\n",
        "        model_ctor=clf_ctor,\n",
        "        ckpt_path=CLF_CKPT,\n",
        "        task=\"clf\",\n",
        "        data_dir=BREAST_DIR,          # ← local data dir\n",
        "        layer_lin_seq_index=first_lin_clf,\n",
        "        pct_neurons=0.20,\n",
        "        repeats=5,\n",
        "        seed=12345\n",
        "    )\n",
        "\n",
        "long_name = \"heal_clf_firstHidden_p20_r5_long\"\n",
        "best_long_path, hist_long = healing_train_constrained(\n",
        "    model=damaged_model2,\n",
        "    mask_dict=mask_dict2,\n",
        "    train_loader=train_loader2,\n",
        "    val_loader=val_loader2,\n",
        "    task=\"clf\",\n",
        "    max_epochs=150,         # longer heal\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    patience=20,\n",
        "    run_name=long_name\n",
        ")\n",
        "\n",
        "m_long = clf_ctor().to(DEVICE)\n",
        "m_long.load_state_dict(torch.load(best_long_path, map_location=DEVICE))\n",
        "metrics_long = evaluate_model(m_long, test_loader2, task=\"clf\")\n",
        "print(\"LONG HEAL (≈150 epochs) TEST:\", metrics_long)\n",
        "\n",
        "# Plot long-heal curves\n",
        "fig_loss_l, fig_metric_l = plot_history(hist_long, long_name, task=\"clf\")\n",
        "\n",
        "# ---- LOG everything to a separate healing CSV ----\n",
        "rows = [\n",
        "    {\n",
        "        \"timestamp\": timestamp(),\n",
        "        \"phase\": \"healing\",\n",
        "        \"dataset\": \"breast_cancer\",\n",
        "        \"task\": \"clf\",\n",
        "        \"stage\": \"baseline\",\n",
        "        \"layer_seq_index\": int(first_lin_clf),\n",
        "        \"pct\": 0.20,\n",
        "        \"repeats\": 5,\n",
        "        \"accuracy\": float(m_before[\"accuracy\"]),\n",
        "        \"f1\": float(m_before[\"f1\"])\n",
        "    },\n",
        "    {\n",
        "        \"timestamp\": timestamp(),\n",
        "        \"phase\": \"healing\",\n",
        "        \"dataset\": \"breast_cancer\",\n",
        "        \"task\": \"clf\",\n",
        "        \"stage\": \"post_damage\",\n",
        "        \"layer_seq_index\": int(first_lin_clf),\n",
        "        \"pct\": 0.20,\n",
        "        \"repeats\": 5,\n",
        "        \"accuracy\": float(m_after[\"accuracy\"]),\n",
        "        \"f1\": float(m_after[\"f1\"])\n",
        "    },\n",
        "    {\n",
        "        \"timestamp\": timestamp(),\n",
        "        \"phase\": \"healing\",\n",
        "        \"dataset\": \"breast_cancer\",\n",
        "        \"task\": \"clf\",\n",
        "        \"stage\": \"healed_short\",\n",
        "        \"layer_seq_index\": int(first_lin_clf),\n",
        "        \"pct\": 0.20,\n",
        "        \"repeats\": 5,\n",
        "        \"epochs\": len(hist_short[\"epoch\"]),\n",
        "        \"accuracy\": float(metrics_short[\"accuracy\"]),\n",
        "        \"f1\": float(metrics_short[\"f1\"]),\n",
        "        \"best_ckpt\": str(best_short_path),\n",
        "        \"fig_loss\": fig_loss_s,\n",
        "        \"fig_metric\": fig_metric_s\n",
        "    },\n",
        "    {\n",
        "        \"timestamp\": timestamp(),\n",
        "        \"phase\": \"healing\",\n",
        "        \"dataset\": \"breast_cancer\",\n",
        "        \"task\": \"clf\",\n",
        "        \"stage\": \"healed_long\",\n",
        "        \"layer_seq_index\": int(first_lin_clf),\n",
        "        \"pct\": 0.20,\n",
        "        \"repeats\": 5,\n",
        "        \"epochs\": len(hist_long[\"epoch\"]),\n",
        "        \"accuracy\": float(metrics_long[\"accuracy\"]),\n",
        "        \"f1\": float(metrics_long[\"f1\"]),\n",
        "        \"best_ckpt\": str(best_long_path),\n",
        "        \"fig_loss\": fig_loss_l,\n",
        "        \"fig_metric\": fig_metric_l\n",
        "    }\n",
        "]\n",
        "\n",
        "for r in rows:\n",
        "    log_result(r, csv_name=\"healing_runs.csv\")\n",
        "\n",
        "print(\"Logged 4 rows to\", RESULTS_DIR / \"healing_runs.csv\")\n",
        "print(\"Short heal plots:\", fig_loss_s, \"|\", fig_metric_s)\n",
        "print(\"Long heal plots:\", fig_loss_l, \"|\", fig_metric_l)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX1EKhTBnSRN",
        "outputId": "3bdd75d4-6a3e-45a9-a769-4611774e5d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exists: True | c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\healing_runs.csv\n",
            "         timestamp    phase        dataset task         stage  \\\n",
            "0  20250813-111348  healing  breast_cancer  clf      baseline   \n",
            "1  20250813-111348  healing  breast_cancer  clf   post_damage   \n",
            "2  20250813-111348  healing  breast_cancer  clf  healed_short   \n",
            "3  20250813-111348  healing  breast_cancer  clf   healed_long   \n",
            "\n",
            "   layer_seq_index  pct  repeats  accuracy        f1  epochs  \\\n",
            "0                0  0.2        5  0.953488  0.962963     NaN   \n",
            "1                0  0.2        5  0.872093  0.899083     NaN   \n",
            "2                0  0.2        5  0.930233  0.944444    15.0   \n",
            "3                0  0.2        5  0.965116  0.971963    46.0   \n",
            "\n",
            "                                           best_ckpt  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\hea...   \n",
            "3  c:\\Users\\Admin\\Desktop\\ffnn-healing\\models\\hea...   \n",
            "\n",
            "                                            fig_loss  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2  c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\he...   \n",
            "3  c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\he...   \n",
            "\n",
            "                                          fig_metric  \n",
            "0                                                NaN  \n",
            "1                                                NaN  \n",
            "2  c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\he...  \n",
            "3  c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\he...  \n"
          ]
        }
      ],
      "source": [
        "# View healing log \n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "csv = RESULTS_DIR / \"healing_runs.csv\"\n",
        "print(\"Exists:\", csv.exists(), \"|\", csv)\n",
        "dfh = pd.read_csv(csv)\n",
        "print(dfh.tail(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yh2-BFnn8tg"
      },
      "source": [
        "We’ll run two tiny healing experiments:\n",
        "\n",
        "Case A (likely recoverable): output layer · 20% neurons · repeats=1\n",
        "\n",
        "Case B (likely non-recoverable): output layer · 20% neurons · repeats=5 (often kills both logits across repeats → model collapses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czkFZiWGn5kC",
        "outputId": "f9ba31ef-93ef-4540-b93b-52641f7a7d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A — BASELINE: {'accuracy': 0.9534883720930233, 'f1': 0.9629629629629629}\n",
            "A — POST-DAMAGE: {'accuracy': 0.9651162790697675, 'f1': 0.972972972972973}\n"
          ]
        }
      ],
      "source": [
        "# A1 — damage: output layer, 20%, repeats=1 \n",
        "set_seed(42)\n",
        "\n",
        "last_lin_clf = layer_seq_indices(clf_ctor)[-1]  # seq index of output Linear\n",
        "\n",
        "damaged_A, mask_A, train_A, val_A, test_A, mA_before, mA_after = \\\n",
        "    apply_progressive_neuron_damage_with_masks(\n",
        "        model_ctor=clf_ctor,\n",
        "        ckpt_path=CLF_CKPT,\n",
        "        task=\"clf\",\n",
        "        data_dir=BREAST_DIR,        # ← local data dir\n",
        "        layer_lin_seq_index=last_lin_clf,\n",
        "        pct_neurons=0.20,           # with 2 output neurons, this will zero 1 of them\n",
        "        repeats=1,\n",
        "        seed=12345\n",
        "    )\n",
        "\n",
        "print(\"A — BASELINE:\", mA_before)\n",
        "print(\"A — POST-DAMAGE:\", mA_after)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlWOWf9Doi6O",
        "outputId": "474b041b-62ec-4d03-8a45-f5920dc6d062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[heal_clf_OUTPUT_p20_r1_short] epoch 001 | train 0.1133 | val 0.0721 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 002 | train 0.1014 | val 0.0674 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 003 | train 0.0803 | val 0.0629 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 004 | train 0.0840 | val 0.0600 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 005 | train 0.0777 | val 0.0585 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 006 | train 0.0578 | val 0.0576 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 008 | train 0.0711 | val 0.0572 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 009 | train 0.0548 | val 0.0569 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 010 | train 0.0542 | val 0.0554 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 011 | train 0.0520 | val 0.0539 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_short] epoch 012 | train 0.0494 | val 0.0535 | metric 0.9765 *\n",
            "A — SHORT HEAL TEST: {'accuracy': 0.9534883720930233, 'f1': 0.9629629629629629}\n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 001 | train 0.0997 | val 0.0708 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 002 | train 0.0921 | val 0.0651 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 003 | train 0.0868 | val 0.0616 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 004 | train 0.0749 | val 0.0587 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 005 | train 0.0728 | val 0.0553 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 006 | train 0.0776 | val 0.0533 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 007 | train 0.0522 | val 0.0522 | metric 0.9765 *\n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 010 | train 0.0614 | val 0.0542 | metric 0.9765 \n",
            "[heal_clf_OUTPUT_p20_r1_long] epoch 020 | train 0.0439 | val 0.0565 | metric 0.9765 \n",
            "[heal_clf_OUTPUT_p20_r1_long] Early stopping at epoch 27. Best val_loss=0.0522\n",
            "A — LONG HEAL TEST: {'accuracy': 0.9534883720930233, 'f1': 0.9629629629629629}\n",
            "A — Logged 4 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\healing_runs.csv\n",
            "A — Plots: c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_OUTPUT_p20_r1_short_loss.png c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_OUTPUT_p20_r1_short_accuracy.png | c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_OUTPUT_p20_r1_long_loss.png c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_OUTPUT_p20_r1_long_accuracy.png\n"
          ]
        }
      ],
      "source": [
        "# A2 — heal short (15) & long (150), evaluate, log\n",
        "A_short = \"heal_clf_OUTPUT_p20_r1_short\"\n",
        "bestA_s, histA_s = healing_train_constrained(\n",
        "    model=damaged_A, mask_dict=mask_A,\n",
        "    train_loader=train_A, val_loader=val_A, task=\"clf\",\n",
        "    max_epochs=15, lr=1e-3, weight_decay=1e-4, patience=5,\n",
        "    run_name=A_short\n",
        ")\n",
        "mA_s = clf_ctor().to(DEVICE)\n",
        "mA_s.load_state_dict(torch.load(bestA_s, map_location=DEVICE))\n",
        "metricsA_s = evaluate_model(mA_s, test_A, task=\"clf\")\n",
        "print(\"A — SHORT HEAL TEST:\", metricsA_s)\n",
        "figA_s_loss, figA_s_metric = plot_history(histA_s, A_short, task=\"clf\")\n",
        "\n",
        "# Recreate the SAME post-damage state for a clean long run\n",
        "damaged_A2, mask_A2, train_A2, val_A2, test_A2, _, _ = \\\n",
        "    apply_progressive_neuron_damage_with_masks(\n",
        "        model_ctor=clf_ctor,\n",
        "        ckpt_path=CLF_CKPT,\n",
        "        task=\"clf\",\n",
        "        data_dir=BREAST_DIR,      # ← local data dir (fixed)\n",
        "        layer_lin_seq_index=last_lin_clf,\n",
        "        pct_neurons=0.20,\n",
        "        repeats=1,\n",
        "        seed=12345\n",
        "    )\n",
        "\n",
        "A_long = \"heal_clf_OUTPUT_p20_r1_long\"\n",
        "bestA_l, histA_l = healing_train_constrained(\n",
        "    model=damaged_A2, mask_dict=mask_A2,\n",
        "    train_loader=train_A2, val_loader=val_A2, task=\"clf\",\n",
        "    max_epochs=150, lr=1e-3, weight_decay=1e-4, patience=20,\n",
        "    run_name=A_long\n",
        ")\n",
        "mA_l = clf_ctor().to(DEVICE)\n",
        "mA_l.load_state_dict(torch.load(bestA_l, map_location=DEVICE))\n",
        "metricsA_l = evaluate_model(mA_l, test_A2, task=\"clf\")\n",
        "print(\"A — LONG HEAL TEST:\", metricsA_l)\n",
        "figA_l_loss, figA_l_metric = plot_history(histA_l, A_long, task=\"clf\")\n",
        "\n",
        "# Log\n",
        "rowsA = [\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"breast_cancer\", \"task\": \"clf\",\n",
        "     \"stage\": \"baseline\", \"layer_seq_index\": int(last_lin_clf), \"pct\": 0.20, \"repeats\": 1,\n",
        "     \"accuracy\": float(mA_before[\"accuracy\"]), \"f1\": float(mA_before[\"f1\"])},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"breast_cancer\", \"task\": \"clf\",\n",
        "     \"stage\": \"post_damage\", \"layer_seq_index\": int(last_lin_clf), \"pct\": 0.20, \"repeats\": 1,\n",
        "     \"accuracy\": float(mA_after[\"accuracy\"]), \"f1\": float(mA_after[\"f1\"])},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"breast_cancer\", \"task\": \"clf\",\n",
        "     \"stage\": \"healed_short\", \"layer_seq_index\": int(last_lin_clf), \"pct\": 0.20, \"repeats\": 1,\n",
        "     \"epochs\": len(histA_s[\"epoch\"]), \"accuracy\": float(metricsA_s[\"accuracy\"]), \"f1\": float(metricsA_s[\"f1\"]),\n",
        "     \"best_ckpt\": str(bestA_s), \"fig_loss\": figA_s_loss, \"fig_metric\": figA_s_metric},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"breast_cancer\", \"task\": \"clf\",\n",
        "     \"stage\": \"healed_long\", \"layer_seq_index\": int(last_lin_clf), \"pct\": 0.20, \"repeats\": 1,\n",
        "     \"epochs\": len(histA_l[\"epoch\"]), \"accuracy\": float(metricsA_l[\"accuracy\"]), \"f1\": float(metricsA_l[\"f1\"]),\n",
        "     \"best_ckpt\": str(bestA_l), \"fig_loss\": figA_l_loss, \"fig_metric\": figA_l_metric},\n",
        "]\n",
        "for r in rowsA:\n",
        "    log_result(r, csv_name=\"healing_runs.csv\")\n",
        "\n",
        "print(\"A — Logged 4 rows to\", RESULTS_DIR / \"healing_runs.csv\")\n",
        "print(\"A — Plots:\", figA_s_loss, figA_s_metric, \"|\", figA_l_loss, figA_l_metric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkCT0WkCokpv",
        "outputId": "40230d3f-b9a7-44b6-e09d-efc5496e995f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B — BASELINE: {'accuracy': 0.9534883720930233, 'f1': 0.9629629629629629}\n",
            "B — POST-DAMAGE: {'accuracy': 0.37209302325581395, 'f1': 0.0}\n"
          ]
        }
      ],
      "source": [
        "# B1 — damage: output layer, 20%, repeats=5 \n",
        "set_seed(42)\n",
        "\n",
        "damaged_B, mask_B, train_B, val_B, test_B, mB_before, mB_after = \\\n",
        "    apply_progressive_neuron_damage_with_masks(\n",
        "        model_ctor=clf_ctor,\n",
        "        ckpt_path=CLF_CKPT,\n",
        "        task=\"clf\",\n",
        "        data_dir=BREAST_DIR,        # ← local data dir\n",
        "        layer_lin_seq_index=last_lin_clf,\n",
        "        pct_neurons=0.20,\n",
        "        repeats=5,\n",
        "        seed=12345\n",
        "    )\n",
        "\n",
        "print(\"B — BASELINE:\", mB_before)\n",
        "print(\"B — POST-DAMAGE:\", mB_after)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh8QgifFom0m",
        "outputId": "8f19830d-a54f-4afb-c32d-7fa053011e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[heal_clf_OUTPUT_p20_r5_short] epoch 001 | train 0.6931 | val 0.6931 | metric 0.3765 *\n",
            "[heal_clf_OUTPUT_p20_r5_short] Early stopping at epoch 6. Best val_loss=0.6931\n",
            "B — SHORT HEAL TEST: {'accuracy': 0.37209302325581395, 'f1': 0.0}\n",
            "[heal_clf_OUTPUT_p20_r5_long] epoch 001 | train 0.6931 | val 0.6931 | metric 0.3765 *\n",
            "[heal_clf_OUTPUT_p20_r5_long] epoch 010 | train 0.6931 | val 0.6931 | metric 0.3765 \n",
            "[heal_clf_OUTPUT_p20_r5_long] epoch 020 | train 0.6931 | val 0.6931 | metric 0.3765 \n",
            "[heal_clf_OUTPUT_p20_r5_long] Early stopping at epoch 21. Best val_loss=0.6931\n",
            "B — LONG HEAL TEST: {'accuracy': 0.37209302325581395, 'f1': 0.0}\n",
            "B — Logged 4 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\healing_runs.csv\n",
            "B — Plots: c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_OUTPUT_p20_r5_short_loss.png c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_OUTPUT_p20_r5_short_accuracy.png | c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_OUTPUT_p20_r5_long_loss.png c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_clf_OUTPUT_p20_r5_long_accuracy.png\n"
          ]
        }
      ],
      "source": [
        "# B2 — heal short (15) & long (150), evaluate, log  \n",
        "B_short = \"heal_clf_OUTPUT_p20_r5_short\"\n",
        "bestB_s, histB_s = healing_train_constrained(\n",
        "    model=damaged_B, mask_dict=mask_B,\n",
        "    train_loader=train_B, val_loader=val_B, task=\"clf\",\n",
        "    max_epochs=15, lr=1e-3, weight_decay=1e-4, patience=5,\n",
        "    run_name=B_short\n",
        ")\n",
        "mB_s = clf_ctor().to(DEVICE)\n",
        "mB_s.load_state_dict(torch.load(bestB_s, map_location=DEVICE))\n",
        "metricsB_s = evaluate_model(mB_s, test_B, task=\"clf\")\n",
        "print(\"B — SHORT HEAL TEST:\", metricsB_s)\n",
        "figB_s_loss, figB_s_metric = plot_history(histB_s, B_short, task=\"clf\")\n",
        "\n",
        "# Fresh same-damage state for long run\n",
        "damaged_B2, mask_B2, train_B2, val_B2, test_B2, _, _ = \\\n",
        "    apply_progressive_neuron_damage_with_masks(\n",
        "        model_ctor=clf_ctor,\n",
        "        ckpt_path=CLF_CKPT,\n",
        "        task=\"clf\",\n",
        "        data_dir=BREAST_DIR,     # ← FIXED\n",
        "        layer_lin_seq_index=last_lin_clf,\n",
        "        pct_neurons=0.20,\n",
        "        repeats=5,\n",
        "        seed=12345\n",
        "    )\n",
        "\n",
        "B_long = \"heal_clf_OUTPUT_p20_r5_long\"\n",
        "bestB_l, histB_l = healing_train_constrained(\n",
        "    model=damaged_B2, mask_dict=mask_B2,\n",
        "    train_loader=train_B2, val_loader=val_B2, task=\"clf\",\n",
        "    max_epochs=150, lr=1e-3, weight_decay=1e-4, patience=20,\n",
        "    run_name=B_long\n",
        ")\n",
        "mB_l = clf_ctor().to(DEVICE)\n",
        "mB_l.load_state_dict(torch.load(bestB_l, map_location=DEVICE))\n",
        "metricsB_l = evaluate_model(mB_l, test_B2, task=\"clf\")\n",
        "print(\"B — LONG HEAL TEST:\", metricsB_l)\n",
        "figB_l_loss, figB_l_metric = plot_history(histB_l, B_long, task=\"clf\")\n",
        "\n",
        "# Log\n",
        "rowsB = [\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"breast_cancer\", \"task\": \"clf\",\n",
        "     \"stage\": \"baseline\", \"layer_seq_index\": int(last_lin_clf), \"pct\": 0.20, \"repeats\": 5,\n",
        "     \"accuracy\": float(mB_before[\"accuracy\"]), \"f1\": float(mB_before[\"f1\"])},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"breast_cancer\", \"task\": \"clf\",\n",
        "     \"stage\": \"post_damage\", \"layer_seq_index\": int(last_lin_clf), \"pct\": 0.20, \"repeats\": 5,\n",
        "     \"accuracy\": float(mB_after[\"accuracy\"]), \"f1\": float(mB_after[\"f1\"])},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"breast_cancer\", \"task\": \"clf\",\n",
        "     \"stage\": \"healed_short\", \"layer_seq_index\": int(last_lin_clf), \"pct\": 0.20, \"repeats\": 5,\n",
        "     \"epochs\": len(histB_s[\"epoch\"]), \"accuracy\": float(metricsB_s[\"accuracy\"]), \"f1\": float(metricsB_s[\"f1\"]),\n",
        "     \"best_ckpt\": str(bestB_s), \"fig_loss\": figB_s_loss, \"fig_metric\": figB_s_metric},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"breast_cancer\", \"task\": \"clf\",\n",
        "     \"stage\": \"healed_long\", \"layer_seq_index\": int(last_lin_clf), \"pct\": 0.20, \"repeats\": 5,\n",
        "     \"epochs\": len(histB_l[\"epoch\"]), \"accuracy\": float(metricsB_l[\"accuracy\"]), \"f1\": float(metricsB_l[\"f1\"]),\n",
        "     \"best_ckpt\": str(bestB_l), \"fig_loss\": figB_l_loss, \"fig_metric\": figB_l_metric},\n",
        "]\n",
        "for r in rowsB:\n",
        "    log_result(r, csv_name=\"healing_runs.csv\")\n",
        "print(\"B — Logged 4 rows to\", RESULTS_DIR / \"healing_runs.csv\")\n",
        "print(\"B — Plots:\", figB_s_loss, figB_s_metric, \"|\", figB_l_loss, figB_l_metric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfmVnTg3ooZV",
        "outputId": "a4ef0ef7-549a-482f-cd0b-528215cfc76c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG — BASELINE: {'mae': 0.37485018372535706, 'rmse': 0.5373355181330539}\n",
            "REG — POST-DAMAGE: {'mae': 0.6136718988418579, 'rmse': 0.9004139597221144}\n"
          ]
        }
      ],
      "source": [
        "# regression: damage first hidden layer, 20%, repeats=5\n",
        "#run on demand\n",
        "set_seed(42)\n",
        "\n",
        "first_lin_reg = layer_seq_indices(reg_ctor)[0]  # seq index 0 for reg model\n",
        "\n",
        "damaged_R, mask_R, train_R, val_R, test_R, mR_before, mR_after = \\\n",
        "    apply_progressive_neuron_damage_with_masks(\n",
        "        model_ctor=reg_ctor,\n",
        "        ckpt_path=REG_CKPT,\n",
        "        task=\"reg\",\n",
        "        data_dir=CAL_DIR,          # ← local data dir\n",
        "        layer_lin_seq_index=first_lin_reg,\n",
        "        pct_neurons=0.20,\n",
        "        repeats=5,\n",
        "        seed=12345\n",
        "    )\n",
        "\n",
        "print(\"REG — BASELINE:\", mR_before)\n",
        "print(\"REG — POST-DAMAGE:\", mR_after)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQmGH6ZGo9g2",
        "outputId": "8b79ace3-1777-4bed-90d9-045ee7c0046f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[heal_reg_firstHidden_p20_r5_short] epoch 001 | train 0.5677 | val 0.4425 | metric 0.6486 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 002 | train 0.4676 | val 0.4181 | metric 0.6257 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 003 | train 0.4479 | val 0.4089 | metric 0.6176 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 004 | train 0.4293 | val 0.4010 | metric 0.6137 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 005 | train 0.4321 | val 0.3963 | metric 0.6076 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 008 | train 0.4227 | val 0.3913 | metric 0.6023 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 009 | train 0.4038 | val 0.3874 | metric 0.5977 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 010 | train 0.4046 | val 0.3908 | metric 0.6000 \n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 011 | train 0.4024 | val 0.3821 | metric 0.5945 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 012 | train 0.3979 | val 0.3743 | metric 0.5903 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 014 | train 0.3894 | val 0.3714 | metric 0.5897 *\n",
            "[heal_reg_firstHidden_p20_r5_short] epoch 015 | train 0.3825 | val 0.3649 | metric 0.5843 *\n",
            "REG — SHORT HEAL TEST: {'mae': 0.3913136422634125, 'rmse': 0.5505083368399453}\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 001 | train 0.6128 | val 0.4473 | metric 0.6520 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 002 | train 0.4845 | val 0.4148 | metric 0.6266 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 003 | train 0.4566 | val 0.4096 | metric 0.6204 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 006 | train 0.4302 | val 0.3946 | metric 0.6058 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 009 | train 0.4090 | val 0.3826 | metric 0.5968 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 010 | train 0.4092 | val 0.3890 | metric 0.6013 \n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 011 | train 0.4018 | val 0.3769 | metric 0.5946 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 014 | train 0.3955 | val 0.3732 | metric 0.5893 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 015 | train 0.3927 | val 0.3716 | metric 0.5883 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 016 | train 0.3868 | val 0.3675 | metric 0.5862 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 017 | train 0.3779 | val 0.3663 | metric 0.5859 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 019 | train 0.3845 | val 0.3643 | metric 0.5820 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 020 | train 0.3927 | val 0.3701 | metric 0.5859 \n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 022 | train 0.3721 | val 0.3589 | metric 0.5768 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 023 | train 0.3702 | val 0.3579 | metric 0.5771 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 024 | train 0.3767 | val 0.3547 | metric 0.5758 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 027 | train 0.3616 | val 0.3519 | metric 0.5740 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 030 | train 0.3639 | val 0.3527 | metric 0.5731 \n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 031 | train 0.3575 | val 0.3484 | metric 0.5682 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 032 | train 0.3602 | val 0.3476 | metric 0.5693 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 033 | train 0.3580 | val 0.3435 | metric 0.5675 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 034 | train 0.3637 | val 0.3430 | metric 0.5697 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 035 | train 0.3547 | val 0.3406 | metric 0.5664 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 036 | train 0.3521 | val 0.3389 | metric 0.5635 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 038 | train 0.3491 | val 0.3379 | metric 0.5645 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 039 | train 0.3488 | val 0.3343 | metric 0.5605 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 040 | train 0.3453 | val 0.3423 | metric 0.5684 \n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 041 | train 0.3533 | val 0.3270 | metric 0.5597 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 050 | train 0.3372 | val 0.3264 | metric 0.5558 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 053 | train 0.3321 | val 0.3253 | metric 0.5553 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 055 | train 0.3328 | val 0.3253 | metric 0.5554 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 060 | train 0.3377 | val 0.3321 | metric 0.5579 \n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 062 | train 0.3396 | val 0.3246 | metric 0.5541 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 063 | train 0.3322 | val 0.3232 | metric 0.5534 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 068 | train 0.3261 | val 0.3223 | metric 0.5539 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 069 | train 0.3341 | val 0.3221 | metric 0.5538 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 070 | train 0.3315 | val 0.3278 | metric 0.5558 \n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 080 | train 0.3290 | val 0.3230 | metric 0.5530 \n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 085 | train 0.3287 | val 0.3219 | metric 0.5520 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 090 | train 0.3279 | val 0.3219 | metric 0.5524 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 091 | train 0.3270 | val 0.3217 | metric 0.5523 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 092 | train 0.3244 | val 0.3212 | metric 0.5519 *\n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 100 | train 0.3271 | val 0.3231 | metric 0.5524 \n",
            "[heal_reg_firstHidden_p20_r5_long] epoch 110 | train 0.3197 | val 0.3222 | metric 0.5520 \n",
            "[heal_reg_firstHidden_p20_r5_long] Early stopping at epoch 112. Best val_loss=0.3212\n",
            "REG — LONG HEAL TEST: {'mae': 0.3671099841594696, 'rmse': 0.5211531197786209}\n",
            "REG — Logged 4 rows to c:\\Users\\Admin\\Desktop\\ffnn-healing\\results\\healing_runs.csv\n",
            "REG — Plots: c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_reg_firstHidden_p20_r5_short_loss.png c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_reg_firstHidden_p20_r5_short_RMSE.png | c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_reg_firstHidden_p20_r5_long_loss.png c:\\Users\\Admin\\Desktop\\ffnn-healing\\figures\\heal_reg_firstHidden_p20_r5_long_RMSE.png\n"
          ]
        }
      ],
      "source": [
        "# R2 — regression healing (short vs long), evaluate, log\n",
        "# run on demand\n",
        "# ---- SHORT HEAL (≈15 epochs) ----\n",
        "R_short = \"heal_reg_firstHidden_p20_r5_short\"\n",
        "bestR_s, histR_s = healing_train_constrained(\n",
        "    model=damaged_R,\n",
        "    mask_dict=mask_R,\n",
        "    train_loader=train_R,\n",
        "    val_loader=val_R,\n",
        "    task=\"reg\",\n",
        "    max_epochs=15,          # quick heal\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    patience=5,\n",
        "    run_name=R_short\n",
        ")\n",
        "\n",
        "mR_s = reg_ctor().to(DEVICE)\n",
        "mR_s.load_state_dict(torch.load(bestR_s, map_location=DEVICE))\n",
        "metricsR_s = evaluate_model(mR_s, test_R, task=\"reg\")\n",
        "print(\"REG — SHORT HEAL TEST:\", metricsR_s)\n",
        "figR_s_loss, figR_s_metric = plot_history(histR_s, R_short, task=\"reg\")\n",
        "\n",
        "# ---- LONG HEAL (≤150 epochs) ----\n",
        "# Recreate the SAME post-damage state so long run starts from identical damage\n",
        "damaged_R2, mask_R2, train_R2, val_R2, test_R2, _, _ = \\\n",
        "    apply_progressive_neuron_damage_with_masks(\n",
        "        model_ctor=reg_ctor,\n",
        "        ckpt_path=REG_CKPT,\n",
        "        task=\"reg\",\n",
        "        data_dir=CAL_DIR,          # ← local data dir (fixed)\n",
        "        layer_lin_seq_index=first_lin_reg,\n",
        "        pct_neurons=0.20,\n",
        "        repeats=5,\n",
        "        seed=12345\n",
        "    )\n",
        "\n",
        "R_long = \"heal_reg_firstHidden_p20_r5_long\"\n",
        "bestR_l, histR_l = healing_train_constrained(\n",
        "    model=damaged_R2,\n",
        "    mask_dict=mask_R2,\n",
        "    train_loader=train_R2,\n",
        "    val_loader=val_R2,\n",
        "    task=\"reg\",\n",
        "    max_epochs=150,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    patience=20,\n",
        "    run_name=R_long\n",
        ")\n",
        "\n",
        "mR_l = reg_ctor().to(DEVICE)\n",
        "mR_l.load_state_dict(torch.load(bestR_l, map_location=DEVICE))\n",
        "metricsR_l = evaluate_model(mR_l, test_R2, task=\"reg\")\n",
        "print(\"REG — LONG HEAL TEST:\", metricsR_l)\n",
        "figR_l_loss, figR_l_metric = plot_history(histR_l, R_long, task=\"reg\")\n",
        "\n",
        "# ---- LOG to healing_runs.csv (mae & rmse) ----\n",
        "rowsR = [\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"california_housing\", \"task\": \"reg\",\n",
        "     \"stage\": \"baseline\", \"layer_seq_index\": int(first_lin_reg), \"pct\": 0.20, \"repeats\": 5,\n",
        "     \"mae\": float(mR_before[\"mae\"]), \"rmse\": float(mR_before[\"rmse\"])},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"california_housing\", \"task\": \"reg\",\n",
        "     \"stage\": \"post_damage\", \"layer_seq_index\": int(first_lin_reg), \"pct\": 0.20, \"repeats\": 5,\n",
        "     \"mae\": float(mR_after[\"mae\"]), \"rmse\": float(mR_after[\"rmse\"])},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"california_housing\", \"task\": \"reg\",\n",
        "     \"stage\": \"healed_short\", \"layer_seq_index\": int(first_lin_reg), \"pct\": 0.20, \"repeats\": 5,\n",
        "     \"epochs\": len(histR_s[\"epoch\"]),\n",
        "     \"mae\": float(metricsR_s[\"mae\"]), \"rmse\": float(metricsR_s[\"rmse\"]),\n",
        "     \"best_ckpt\": str(bestR_s), \"fig_loss\": figR_s_loss, \"fig_metric\": figR_s_metric},\n",
        "    {\"timestamp\": timestamp(), \"phase\": \"healing\", \"dataset\": \"california_housing\", \"task\": \"reg\",\n",
        "     \"stage\": \"healed_long\", \"layer_seq_index\": int(first_lin_reg), \"pct\": 0.20, \"repeats\": 5,\n",
        "     \"epochs\": len(histR_l[\"epoch\"]),\n",
        "     \"mae\": float(metricsR_l[\"mae\"]), \"rmse\": float(metricsR_l[\"rmse\"]),\n",
        "     \"best_ckpt\": str(bestR_l), \"fig_loss\": figR_l_loss, \"fig_metric\": figR_l_metric},\n",
        "]\n",
        "for r in rowsR:\n",
        "    log_result(r, csv_name=\"healing_runs.csv\")\n",
        "\n",
        "print(\"REG — Logged 4 rows to\", RESULTS_DIR / \"healing_runs.csv\")\n",
        "print(\"REG — Plots:\", figR_s_loss, figR_s_metric, \"|\", figR_l_loss, figR_l_metric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bkv2QCcMpeQY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ffnn-healing",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
